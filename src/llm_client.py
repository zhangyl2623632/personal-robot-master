# llm_client.py
# é€šç”¨å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ”¯æŒ DeepSeek / OpenAI / Qwen / Moonshot / SparkDesk ç­‰
# æ”¯æŒä¸¥æ ¼æ¨¡å¼ã€ç»“æ„åŒ–è¾“å‡ºã€å…ƒæ•°æ®å¢å¼ºã€æ„å›¾è¯†åˆ«

import os
import re
import logging
import requests
import time
import traceback
import random
import hashlib
from datetime import datetime, timedelta
from functools import lru_cache, wraps
from requests.adapters import Retry, HTTPAdapter
import json
from typing import List, Dict, Any, Optional, Union, Generator, Callable, Tuple
from abc import ABC, abstractmethod
from dataclasses import dataclass
from enum import Enum
from pydantic import BaseModel, ValidationError

# å‡è®¾ä½ æœ‰ä¸€ä¸ª config æ¨¡å—ï¼Œè‹¥æ²¡æœ‰ï¼Œå¯æ›¿æ¢ä¸º dotenv æˆ–ç¡¬ç¼–ç 
try:
    from src.config import global_config
except ImportError:
    # å¦‚æœæ²¡æœ‰ configï¼Œæä¾›é»˜è®¤é…ç½®ï¼ˆä½ å¯è‡ªè¡Œä¿®æ”¹ï¼‰
    class MockConfig:
        MODEL_PROVIDER = "deepseek"  # å¯é€‰: deepseek, openai, qwen, moonshot, spark
        MODEL_NAME = "deepseek-chat"
        MODEL_URL = "https://api.deepseek.com/v1/chat/completions"
        API_KEY = os.getenv("DEEPSEEK_API_KEY") or "sk-xxx"
        TEMPERATURE = 0.1
        MAX_TOKENS = 2048
        TIMEOUT = 30

    # ä½¿ç”¨mocké…ç½®
    global_config = MockConfig()

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# æ·»åŠ æ›´è¯¦ç»†çš„æ—¥å¿—è®°å½•å™¨
api_logger = logging.getLogger('llm_client.api')
api_logger.setLevel(logging.INFO)

# å®šä¹‰å“åº”ç¼“å­˜ç±»
class ResponseCache:
    """LLMå“åº”ç¼“å­˜"""
    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.cache = {}
        self.max_size = max_size
        self.ttl = ttl  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        
    def _get_cache_key(self, prompt: str, context: Optional[List[str]] = None, history: Optional[List[Dict[str, str]]] = None) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        combined = prompt
        if context:
            combined += '|||'.join(context)
        if history:
            combined += '|||'.join([f"{h['role']}:{h['content']}" for h in history])
        return hashlib.md5(combined.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[str]:
        """è·å–ç¼“å­˜é¡¹"""
        if key in self.cache:
            item = self.cache[key]
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if datetime.now() < item['expires_at']:
                api_logger.debug(f"ç¼“å­˜å‘½ä¸­: {key[:10]}...")
                return item['response']
            else:
                api_logger.debug(f"ç¼“å­˜è¿‡æœŸ: {key[:10]}...")
                del self.cache[key]  # æ¸…ç†è¿‡æœŸç¼“å­˜
        return None
    
    def set(self, key: str, response: str):
        """è®¾ç½®ç¼“å­˜é¡¹"""
        # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œç§»é™¤æœ€æ—§çš„é¡¹
        if len(self.cache) >= self.max_size:
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
            api_logger.debug(f"ç¼“å­˜å·²æ»¡ï¼Œç§»é™¤æœ€æ—§é¡¹")
            
        # è®¾ç½®ç¼“å­˜é¡¹
        self.cache[key] = {
            'response': response,
            'expires_at': datetime.now() + timedelta(seconds=self.ttl)
        }
        api_logger.debug(f"ç¼“å­˜è®¾ç½®: {key[:10]}...")
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        api_logger.debug("ç¼“å­˜å·²æ¸…ç©º")

# åˆ›å»ºå…¨å±€ç¼“å­˜å®ä¾‹
response_cache = ResponseCache()

# å®šä¹‰æ¨¡å‹æä¾›å•†æšä¸¾
class ModelProvider(str, Enum):
    DEEPSEEK = "deepseek"
    OPENAI = "openai"
    QWEN = "qwen"
    MOONSHOT = "moonshot"
    SPARK = "spark"
    # å¯ä»¥ç»§ç»­æ‰©å±•

# å®šä¹‰ä¸€äº›å·¥å…·å‡½æ•°
# ======================== 
# ğŸ› ï¸ å·¥å…·å‡½æ•° 
# ======================== 
def preprocess_query(query: str) -> str:
    """é¢„å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    # å»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œç¬¦
    processed = ' '.join(query.strip().split())
    # è½¬å°å†™ï¼ˆå¯é€‰ï¼Œæ ¹æ®éœ€è¦ï¼‰
    # processed = processed.lower()
    return processed

def enhance_context_with_metadata(context: str) -> str:
    """ç”¨å…ƒæ•°æ®å¢å¼ºä¸Šä¸‹æ–‡"""
    # æå–å…ƒæ•°æ®
    metadata = extract_metadata_from_text(context)
    
    # æ·»åŠ å…ƒæ•°æ®åˆ°ä¸Šä¸‹æ–‡
    enhanced_context = ""
    if 'title' in metadata:
        enhanced_context += f"ã€æ ‡é¢˜ã€‘{metadata['title']}\n\n"
    
    enhanced_context += context
    return enhanced_context

def extract_metadata_from_text(text: str) -> Dict[str, str]:
    """ä»æ–‡æœ¬ä¸­æå–å…ƒæ•°æ®"""
    metadata = {}
    lines = text.strip().split('\n')[:200]  # åªå¤„ç†å‰200è¡Œ

    # æ­£åˆ™æ¨¡å¼åŒ¹é…å¸¸è§å…ƒæ•°æ®
    patterns = {
        'version': r'(Version|ç‰ˆæœ¬)[\s:]+([\d\.]+)',
        # æ—¥æœŸå…è®¸æ›´å®½æ¾çš„æ ¼å¼ï¼Œä»¥åŒ¹é…â€œ28th August, 2025â€ç­‰
        'date': r'(Date|æ—¥æœŸ)[\s:]+([^\n]+)',
        'author': r'(Author|ä½œè€…)[\s:]+([^\n]+)',
        'prepared_by': r'(Prepared by|Prepared)[\s:]+([^\n]+)',
        'release': r'(Release|å‘å¸ƒ)[\s:]+([^\n]+)',
        'release_date': r'(Release Date)[\s:]+([^\n]+)',
    }

    # æå–å…ƒæ•°æ®
    for key, pattern in patterns.items():
        for line in lines[:50]:  # åªåœ¨å‰50è¡ŒæŸ¥æ‰¾
            match = re.search(pattern, line, re.IGNORECASE)
            if match:
                # å…³é”®ä¿®å¤ï¼šä½¿ç”¨åŒ¹é…å€¼ç»„è€Œä¸æ˜¯æ ‡ç­¾ç»„
                # group(1) æ˜¯æ ‡ç­¾ï¼ˆå¦‚ Author/ä½œè€…ï¼‰ï¼Œgroup(2) æ‰æ˜¯å®é™…å€¼
                value_group_index = 2
                # å¯¹éæ•°å€¼ç±»çš„æå–åšæ¸…ç†
                value = match.group(value_group_index).strip()
                # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ ‡ç‚¹æˆ–å¤šä½™ç©ºæ ¼
                value = re.sub(r'[\s\-:]+$', '', value)
                metadata[key] = value

    # å¯å‘å¼æå–ä¸»æ ‡é¢˜
    if 'title' not in metadata:
        for line in lines[:10]:
            stripped = line.strip()
            if stripped and len(stripped) > 5 and not re.search(r'^(Version|Date|Author|Release|Prepared|Document)', stripped, re.I):
                metadata['title'] = stripped
                break

    # æå–å…³é”®æ®µè½ï¼ˆåŠŸèƒ½/é…ç½®/è´¹ç”¨/æµç¨‹ï¼‰
    key_sections = {
        'main_functions': [], 
        'system_config': [], 
        'fee_structure': [], 
        'process_flow': [],
        'data_structures': []
    }
    current_section = None

    for i, line in enumerate(lines[:200]):
        stripped = line.strip()
        if not stripped: continue

        # è¯†åˆ«ç« èŠ‚æ ‡é¢˜ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
        if re.search(r'åŠŸèƒ½|Functions|Features', stripped, re.I):
            current_section = 'main_functions'
        elif re.search(r'é…ç½®|Configuration|Settings', stripped, re.I):
            current_section = 'system_config'
        elif re.search(r'è´¹ç”¨|Fee|Cost|Price|è´¹ç‡', stripped, re.I):
            current_section = 'fee_structure'
        elif re.search(r'æµç¨‹|Process|Steps|æ­¥éª¤', stripped, re.I):
            current_section = 'process_flow'
        elif re.search(r'æ•°æ®ç»“æ„|Data Structure|è¡¨æ ¼|Table', stripped, re.I):
            current_section = 'data_structures'
        elif re.search(r'^\d+\.', stripped):  # æ•°å­—æ ‡é¢˜
            pass  # ä¿æŒå½“å‰section
        elif stripped and current_section and not stripped.endswith(':') and i < len(lines) - 1 and lines[i+1].strip():
            # å°†å†…å®¹æ·»åŠ åˆ°å½“å‰section
            key_sections[current_section].append(stripped)

    # å°†åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    for key, value in key_sections.items():
        if value:
            metadata[key] = '\n'.join(value[:5])  # åªä¿ç•™å‰5ä¸ªé¡¹ç›®

    # è§„èŒƒåŒ–ï¼šå°†â€œPrepared byâ€æ˜ å°„ä¸ºä½œè€…ï¼›å°†å‘å¸ƒæ—¥æœŸæ˜ å°„ä¸ºåˆ›å»ºæ—¶é—´
    if 'author' not in metadata and 'prepared_by' in metadata:
        metadata['author'] = metadata['prepared_by']
    if 'created' not in metadata:
        for tkey in ['release_date', 'release', 'date']:
            if tkey in metadata:
                metadata['created'] = metadata[tkey]
                break

    return metadata

# ======================== 
# ğŸ¯ å®¢æˆ·ç«¯æŠ½è±¡åŸºç±» 
# ======================== 
class BaseLLMClient(ABC):
    """LLM å®¢æˆ·ç«¯æŠ½è±¡åŸºç±»"""

    def __init__(self, config=None):
        self.config = config or global_config
        self.provider = ModelProvider(self.config.MODEL_PROVIDER.lower())
        # ä½¿ç”¨getattrç¡®ä¿å³ä½¿é…ç½®é¡¹ä¸å­˜åœ¨ä¹Ÿä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        # æ ¹æ®æ¨¡å‹æä¾›å•†è·å–å¯¹åº”çš„APIå¯†é’¥
        if self.provider == ModelProvider.DEEPSEEK:
            self.api_key = getattr(self.config, 'DEEPSEEK_API_KEY', None) or os.getenv('DEEPSEEK_API_KEY')
        elif self.provider == ModelProvider.QWEN:
            self.api_key = getattr(self.config, 'QWEN_API_KEY', None) or os.getenv('QWEN_API_KEY')
        elif self.provider == ModelProvider.OPENAI:
            self.api_key = getattr(self.config, 'OPENAI_API_KEY', None) or os.getenv('OPENAI_API_KEY')
        elif self.provider == ModelProvider.MOONSHOT:
            self.api_key = getattr(self.config, 'MOONSHOT_API_KEY', None) or os.getenv('MOONSHOT_API_KEY')
        else:
            # é»˜è®¤ä½¿ç”¨é€šç”¨API_KEY
            self.api_key = getattr(self.config, 'API_KEY', None) or os.getenv('API_KEY')
        
        self.model_name = self.config.MODEL_NAME
        # å…è®¸å°†è¶…æ—¶é…ç½®ä¸ºäºŒå…ƒç»„ (connect_timeout, read_timeout) ä»¥æé«˜ç¨³å¥æ€§
        # é»˜è®¤é‡‡ç”¨è¾ƒå®½æ¾çš„è®¾ç½®ä»¥é™ä½ç½‘ç»œæ³¢åŠ¨å¯¼è‡´çš„è¿æ¥é‡ç½®
        self.timeout = getattr(self.config, 'TIMEOUT', (10, 60))
        self.temperature = getattr(self.config, 'TEMPERATURE', 0.1)
        self.max_tokens = getattr(self.config, 'MAX_TOKENS', 2048)
        
        # é‡è¯•é…ç½®
        self.max_retries = getattr(self.config, 'RETRY_MAX_ATTEMPTS', 3)
        self.backoff_factor = getattr(self.config, 'RETRY_BACKOFF_FACTOR', 1.5)
        self.status_forcelist = getattr(self.config, 'RETRY_STATUS_FORCELIST', [429, 500, 502, 503, 504])
        
        # è´Ÿè½½å‡è¡¡é…ç½®
        self.api_urls = getattr(self.config, f'{self.provider.upper()}_API_URLS', [self._get_default_api_url()])
        self.current_url_index = 0
        
        # é™æµé…ç½®
        self.rate_limit_per_minute = getattr(self.config, f'{self.provider.upper()}_RATE_LIMIT', 60)
        self.request_timestamps = []
        
        # æ•…éšœè½¬ç§»é…ç½®
        self.failover_enabled = getattr(self.config, 'FAILOVER_ENABLED', True)
        self.failover_providers = getattr(self.config, 'FAILOVER_PROVIDERS', [])
        
        # åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ä¼šè¯
        self.session = self._create_session()
        
        # ä¿å­˜æœ€è¿‘ä¸€æ¬¡æˆåŠŸçš„å“åº”ä½œä¸ºå¤‡ç”¨
        self._last_successful_response = None
        
        # å¥åº·çŠ¶æ€æ ‡å¿—
        self._is_healthy = True
        
        # å“åº”è®¡æ•°å™¨
        self.response_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'cache_hits': 0,
            'total_tokens_used': 0
        }
        
        # ç»“æ„åŒ–è¾“å‡ºé…ç½®
        self.structured_output_enabled = getattr(self.config, 'STRUCTURED_OUTPUT_ENABLED', False)
        self.structured_output_schema = getattr(self.config, 'STRUCTURED_OUTPUT_SCHEMA', None)

    def _get_default_api_url(self) -> str:
        """è·å–é»˜è®¤API URL"""
        urls = {
            ModelProvider.DEEPSEEK: "https://api.deepseek.com/v1/chat/completions",
            ModelProvider.OPENAI: "https://api.openai.com/v1/chat/completions",
            ModelProvider.MOONSHOT: "https://api.moonshot.cn/v1/chat/completions",
            ModelProvider.QWEN: "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
        }
        return urls.get(self.provider, urls[ModelProvider.DEEPSEEK])
    
    def _create_session(self) -> requests.Session:
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„requestsä¼šè¯"""
        session = requests.Session()
        # æ™ºèƒ½é‡è¯•ç­–ç•¥ï¼šæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
        retry = Retry(
            total=self.max_retries,
            backoff_factor=self.backoff_factor,
            status_forcelist=self.status_forcelist,
            allowed_methods=["POST"],  # åªå¯¹POSTè¯·æ±‚é‡è¯•
            raise_on_status=False,  # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…å¤„ç†çŠ¶æ€ç 
            respect_retry_after_header=True  # å°Šé‡Retry-Afterå¤´éƒ¨
        )
        adapter = HTTPAdapter(max_retries=retry, pool_connections=20, pool_maxsize=20, pool_block=False)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        
        # æ·»åŠ è¯·æ±‚/å“åº”é’©å­ç”¨äºæ—¥å¿—è®°å½•
        session.hooks['response'].append(self._response_hook)
        
        return session
    
    def _response_hook(self, response, *args, **kwargs):
        """å“åº”é’©å­ï¼Œç”¨äºè®°å½•è¯¦ç»†çš„APIè°ƒç”¨ä¿¡æ¯"""
        if hasattr(response, 'request'):
            request = response.request
            api_logger.debug(f"APIè°ƒç”¨: {request.method} {request.url}")
            api_logger.debug(f"çŠ¶æ€ç : {response.status_code}")
            
            # è®°å½•è¯·æ±‚ä½“å¤§å°ï¼ˆé¿å…è®°å½•æ•æ„Ÿä¿¡æ¯ï¼‰
            if request.body:
                api_logger.debug(f"è¯·æ±‚ä½“å¤§å°: {len(request.body)} å­—èŠ‚")
                
            # è®°å½•å“åº”ä½“å¤§å°
            response_size = len(response.content) if response.content else 0
            api_logger.debug(f"å“åº”ä½“å¤§å°: {response_size} å­—èŠ‚")
    
    def _check_rate_limit(self):
        """æ£€æŸ¥å¹¶åº”ç”¨é€Ÿç‡é™åˆ¶"""
        current_time = time.time()
        # ç§»é™¤1åˆ†é’Ÿå‰çš„æ—¶é—´æˆ³
        self.request_timestamps = [t for t in self.request_timestamps if current_time - t < 60]
        
        # å¦‚æœè¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…
        if len(self.request_timestamps) >= self.rate_limit_per_minute:
            wait_time = 60 - (current_time - self.request_timestamps[0])
            if wait_time > 0:
                api_logger.info(f"è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.2f} ç§’")
                time.sleep(wait_time)
        
        # è®°å½•å½“å‰è¯·æ±‚æ—¶é—´
        self.request_timestamps.append(current_time)
    
    def _get_next_api_url(self) -> str:
        """è·å–ä¸‹ä¸€ä¸ªAPI URLï¼ˆè½®è¯¢è´Ÿè½½å‡è¡¡ï¼‰"""
        url = self.api_urls[self.current_url_index]
        # æ›´æ–°ç´¢å¼•ç”¨äºä¸‹æ¬¡è°ƒç”¨
        self.current_url_index = (self.current_url_index + 1) % len(self.api_urls)
        return url
    
    def _validate_structured_response(self, response: str, schema: Optional[BaseModel] = None) -> Tuple[bool, Any]:
        """éªŒè¯ç»“æ„åŒ–å“åº”æ˜¯å¦ç¬¦åˆschema"""
        if not schema:
            return True, response
        
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            json_match = re.search(r'```json\n(.*?)\n```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                data = json.loads(json_str)
                # ä½¿ç”¨PydanticéªŒè¯
                validated_data = schema(**data)
                return True, validated_data.model_dump()
            else:
                # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                data = json.loads(response)
                validated_data = schema(**data)
                return True, validated_data.model_dump()
        except (json.JSONDecodeError, ValidationError, TypeError) as e:
            api_logger.error(f"ç»“æ„åŒ–å“åº”éªŒè¯å¤±è´¥: {str(e)}")
            return False, None
    
    def _perform_failover(self) -> bool:
        """æ‰§è¡Œæ•…éšœè½¬ç§»åˆ°å¤‡ç”¨æä¾›å•†"""
        if not self.failover_enabled or not self.failover_providers:
            api_logger.warning("æ•…éšœè½¬ç§»æœªå¯ç”¨æˆ–æœªé…ç½®å¤‡ç”¨æä¾›å•†")
            return False
        
        # è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„æä¾›å•†
        for provider_name in self.failover_providers:
            try:
                provider = ModelProvider(provider_name.lower())
                api_logger.info(f"å°è¯•æ•…éšœè½¬ç§»åˆ°æä¾›å•†: {provider}")
                
                # æ›´æ–°å½“å‰æä¾›å•†é…ç½®
                self.provider = provider
                # è·å–æ–°æä¾›å•†çš„APIå¯†é’¥
                if provider == ModelProvider.DEEPSEEK:
                    self.api_key = getattr(self.config, 'DEEPSEEK_API_KEY', None) or os.getenv('DEEPSEEK_API_KEY')
                elif provider == ModelProvider.QWEN:
                    self.api_key = getattr(self.config, 'QWEN_API_KEY', None) or os.getenv('QWEN_API_KEY')
                elif provider == ModelProvider.OPENAI:
                    self.api_key = getattr(self.config, 'OPENAI_API_KEY', None) or os.getenv('OPENAI_API_KEY')
                elif provider == ModelProvider.MOONSHOT:
                    self.api_key = getattr(self.config, 'MOONSHOT_API_KEY', None) or os.getenv('MOONSHOT_API_KEY')
                
                # éªŒè¯æ–°æä¾›å•†æ˜¯å¦å¯ç”¨
                if self.validate_api_key():
                    api_logger.info(f"æ•…éšœè½¬ç§»æˆåŠŸ: {provider}")
                    return True
            except Exception as e:
                api_logger.error(f"æ•…éšœè½¬ç§»åˆ° {provider_name} å¤±è´¥: {str(e)}")
                
        return False

    @abstractmethod
    def _get_headers(self) -> Dict[str, str]:
        pass

    @abstractmethod
    def _get_api_url(self) -> str:
        pass

    @abstractmethod
    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:
        pass

    def generate_response(
        self,
        prompt: str,
        context: Optional[List[str]] = None,
        history: Optional[List[Dict[str, str]]] = None,
        stream: bool = False,
        cache_enabled: bool = True,
        structured_schema: Optional[BaseModel] = None
    ) -> Union[Optional[str], Dict[str, Any], Generator[str, None, None]]:  # æµå¼è¿”å›ç”Ÿæˆå™¨
        """ç”Ÿæˆå›ç­”ï¼Œå¸¦é‡è¯•æœºåˆ¶ã€ç¼“å­˜å’Œç»“æ„åŒ–è¾“å‡ºéªŒè¯"""
        # æ›´æ–°è¯·æ±‚è®¡æ•°
        self.response_stats['total_requests'] += 1
        
        # éæµå¼è¯·æ±‚ä¸”å¯ç”¨ç¼“å­˜æ—¶ï¼Œå°è¯•ä»ç¼“å­˜è·å–
        if not stream and cache_enabled:
            cache_key = response_cache._get_cache_key(prompt, context, history)
            cached_response = response_cache.get(cache_key)
            if cached_response:
                self.response_stats['cache_hits'] += 1
                api_logger.info(f"ä»ç¼“å­˜è¿”å›å“åº”ï¼Œç¼“å­˜å‘½ä¸­ç‡: {self._get_cache_hit_rate():.2f}%")
                
                # å¦‚æœéœ€è¦ç»“æ„åŒ–è¾“å‡ºï¼ŒéªŒè¯ç¼“å­˜çš„å“åº”
                if structured_schema:
                    is_valid, validated_data = self._validate_structured_response(cached_response, structured_schema)
                    if is_valid:
                        return validated_data
                    # å¦‚æœç¼“å­˜çš„å“åº”ä¸ç¬¦åˆschemaï¼Œç»§ç»­è·å–æ–°å“åº”
                    api_logger.warning("ç¼“å­˜çš„å“åº”ä¸ç¬¦åˆschemaï¼Œè·å–æ–°å“åº”")
                else:
                    return cached_response
        
        try:
            # æ£€æŸ¥é€Ÿç‡é™åˆ¶
            self._check_rate_limit()
            
            messages = self._build_messages(prompt, context, history)
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            if stream:
                return self._call_api_with_retry_stream(messages)
            else:
                response = self._call_api_with_retry(messages)
                
                # è®°å½•å“åº”æ—¶é—´
                response_time = time.time() - start_time
                logger.info(f"ç”Ÿæˆå›ç­”æˆåŠŸï¼Œé•¿åº¦: {len(response) if response else 0} å­—ç¬¦ï¼Œå“åº”æ—¶é—´: {response_time:.2f}ç§’")
                
                # æ›´æ–°æˆåŠŸè®¡æ•°
                if response:
                    self.response_stats['successful_requests'] += 1
                    self._last_successful_response = response
                    self._is_healthy = True
                    
                    # å¦‚æœå¯ç”¨ç¼“å­˜ï¼Œä¸”å“åº”è´¨é‡è¾¾æ ‡ï¼Œä¿å­˜åˆ°ç¼“å­˜
                    if cache_enabled and self._should_cache_response(response):
                        cache_key = response_cache._get_cache_key(prompt, context, history)
                        response_cache.set(cache_key, response)
                    
                    # å¤„ç†ç»“æ„åŒ–è¾“å‡ºéªŒè¯
                    if structured_schema or self.structured_output_enabled:
                        schema = structured_schema or self.structured_output_schema
                        if schema:
                            is_valid, validated_data = self._validate_structured_response(response, schema)
                            if is_valid:
                                return validated_data
                            else:
                                # éªŒè¯å¤±è´¥ï¼Œå°è¯•å†æ¬¡ç”Ÿæˆ
                                api_logger.warning("ç»“æ„åŒ–è¾“å‡ºéªŒè¯å¤±è´¥ï¼Œå°è¯•é‡æ–°ç”Ÿæˆ")
                                return self.generate_response(prompt, context, history, stream, False, structured_schema)
                
                return response
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›ç­”å¼‚å¸¸: {str(e)}")
            traceback.print_exc()
            
            # æ›´æ–°å¤±è´¥è®¡æ•°
            self.response_stats['failed_requests'] += 1
            
            # å°è¯•æ•…éšœè½¬ç§»
            if not stream and self.failover_enabled and self._perform_failover():
                api_logger.info("æ•…éšœè½¬ç§»åé‡æ–°å°è¯•è¯·æ±‚")
                return self.generate_response(prompt, context, history, stream, cache_enabled, structured_schema)
            
            # è¿”å›ä¸Šæ¬¡æˆåŠŸçš„å“åº”ä½œä¸ºåå¤‡
            if self._last_successful_response:
                logger.warning("ä½¿ç”¨ä¸Šæ¬¡æˆåŠŸçš„å“åº”ä½œä¸ºåå¤‡")
                return self._last_successful_response
            
            # æä¾›é»˜è®¤å›å¤
            default_response = self._get_default_response(prompt)
            # å¦‚æœå¯ç”¨ç»“æ„åŒ–è¾“å‡ºï¼Œä¸ºé»˜è®¤å›å¤åˆ›å»ºç»“æ„åŒ–æ ¼å¼
            if structured_schema:
                try:
                    # å°è¯•åˆ›å»ºä¸€ä¸ªç¬¦åˆschemaçš„æœ€å°å“åº”
                    return {"error": True, "message": default_response}
                except:
                    pass
            return default_response

    def _should_cache_response(self, response_text: str) -> bool:
        """åˆ¤æ–­å“åº”æ˜¯å¦é€‚åˆå†™å…¥ç¼“å­˜ï¼Œé¿å…ç¼“å­˜é€šç”¨æ‹’ç­”æˆ–è¿‡çŸ­å†…å®¹"""
        try:
            text = (response_text or "").strip()
            if len(text) < 30:
                api_logger.info("å“åº”è¿‡çŸ­ï¼Œä¸å†™å…¥ç¼“å­˜")
                return False
            generic_patterns = [
                "æ— æ³•å›ç­”", "æŠ±æ­‰", "æˆ‘ä¸çŸ¥é“", "æš‚æ—¶ä¸å¯ç”¨", "ç¨åå†è¯•",
                "ä¸èƒ½æä¾›", "æ— æƒè®¿é—®"
            ]
            if any(pat in text for pat in generic_patterns):
                api_logger.info("æ£€æµ‹åˆ°é€šç”¨æ‹’ç­”è¯­å¥ï¼Œä¸å†™å…¥ç¼“å­˜")
                return False
            return True
        except Exception:
            return True
    
    def _get_cache_hit_rate(self) -> float:
        """è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡"""
        total = self.response_stats['total_requests']
        if total == 0:
            return 0.0
        return (self.response_stats['cache_hits'] / total) * 100
    
    def get_response_stats(self) -> Dict[str, int]:
        """è·å–å“åº”ç»Ÿè®¡ä¿¡æ¯"""
        return self.response_stats.copy()
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.response_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'cache_hits': 0,
            'total_tokens_used': 0
        }

    def _get_default_response(self, prompt: str) -> str:
        """è·å–é»˜è®¤å›å¤ï¼Œå½“æ‰€æœ‰APIè°ƒç”¨éƒ½å¤±è´¥æ—¶"""
        self._is_healthy = False
        logger.warning(f"APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤å›å¤")
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹è¿”å›ä¸åŒçš„é»˜è®¤å›å¤
        query_lower = prompt.lower()
        if any(word in query_lower for word in ["æ¦‚è¿°", "ä»‹ç»", "æ€»ç»“", "ä¸»è¦å†…å®¹"]):
            return "æ ¹æ®ç°æœ‰èµ„æ–™ï¼Œæ— æ³•å›ç­”è¯¥é—®é¢˜ã€‚å½“å‰æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        elif any(word in query_lower for word in ["è¡¨æ ¼", "è´¹ç‡", "ä»·æ ¼", "è´¹ç”¨"]):
            return "æ ¹æ®ç°æœ‰èµ„æ–™ï¼Œæ— æ³•å›ç­”è¯¥é—®é¢˜ã€‚å½“å‰æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        elif any(word in query_lower for word in ["æµç¨‹", "æ­¥éª¤", "å¦‚ä½•"]):
            return "æ ¹æ®ç°æœ‰èµ„æ–™ï¼Œæ— æ³•å›ç­”è¯¥é—®é¢˜ã€‚å½“å‰æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        else:
            return "æ ¹æ®ç°æœ‰èµ„æ–™ï¼Œæ— æ³•å›ç­”è¯¥é—®é¢˜ã€‚å½“å‰æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
            
    def generate_streaming_response(
        self,
        prompt: str,
        context: Optional[List[str]] = None,
        history: Optional[List[Dict[str, str]]] = None,
        cache_enabled: bool = False  # æµå¼å“åº”é»˜è®¤ä¸ä½¿ç”¨ç¼“å­˜
    ) -> Generator[str, None, None]:
        """ç”Ÿæˆæµå¼å›ç­”ï¼Œæä¾›å¯¹æµå¼å“åº”çš„ç›´æ¥è®¿é—®"""
        # ç¡®ä¿streamå‚æ•°ä¸ºTrue
        return self.generate_response(prompt, context, history, stream=True, cache_enabled=cache_enabled)
        
    def generate_batched_response(
        self,
        prompts: List[str],
        contexts: Optional[List[List[str]]] = None,
        history: Optional[List[Dict[str, str]]] = None,
        batch_size: int = 5
    ) -> List[Optional[str]]:
        """æ‰¹é‡ç”Ÿæˆå›ç­”ï¼Œä¼˜åŒ–å¤šä¸ªç›¸ä¼¼æŸ¥è¯¢çš„å¤„ç†"""
        results = []
        
        # å¦‚æœæ²¡æœ‰æä¾›contextsï¼Œä¸ºæ¯ä¸ªpromptåˆ›å»ºç©ºcontext
        if contexts is None:
            contexts = [None] * len(prompts)
            
        # ç¡®ä¿contextså’Œpromptsé•¿åº¦ä¸€è‡´
        assert len(prompts) == len(contexts), "promptså’Œcontextsé•¿åº¦å¿…é¡»ä¸€è‡´"
        
        # æ‰¹é‡å¤„ç†
        for i in range(0, len(prompts), batch_size):
            batch_prompts = prompts[i:i+batch_size]
            batch_contexts = contexts[i:i+batch_size]
            
            # ä¸ºæ¯ä¸ªæŸ¥è¯¢ç”Ÿæˆå›ç­”
            for j, (prompt, context) in enumerate(zip(batch_prompts, batch_contexts)):
                try:
                    result = self.generate_response(prompt, context, history, stream=False)
                    results.append(result)
                except Exception as e:
                    logger.error(f"æ‰¹é‡å¤„ç†ç¬¬{i+j}ä¸ªæŸ¥è¯¢å¤±è´¥: {str(e)}")
                    results.append(None)
            
            # é¿å…è§¦å‘APIé€Ÿç‡é™åˆ¶
            if i + batch_size < len(prompts):
                time.sleep(1)  # æ¯ä¸ªæ‰¹æ¬¡ä¹‹é—´ç­‰å¾…1ç§’
        
        return results

    def _build_messages(
        self,
        prompt: str,
        context: Optional[List[str]] = None,
        history: Optional[List[Dict[str, str]]] = None
    ) -> List[Dict[str, str]]:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨"""
        messages = [{"role": "system", "content": global_config.SYSTEM_PROMPT}]

        if history:
            messages.extend(history)

        processed_query = preprocess_query(prompt)

        if context:
            enhanced_contexts = []
            for i, ctx in enumerate(context):
                enhanced_ctx = enhance_context_with_metadata(ctx)
                enhanced_contexts.append(f"ã€ä¸Šä¸‹æ–‡ {i+1}ã€‘\n{enhanced_ctx}")

            context_text = "\n\n".join(enhanced_contexts)
            user_content = f"{context_text}\n\n---\n\nã€ç”¨æˆ·é—®é¢˜ã€‘\n{processed_query}"
        else:
            user_content = processed_query

        messages.append({"role": "user", "content": user_content})
        return messages

    def _call_api_with_retry(self, messages: List[Dict[str, str]]) -> Optional[str]:
        """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨ï¼ˆéæµå¼ï¼‰"""
        attempt = 0
        while attempt < self.max_retries:
            attempt += 1
            try:
                # æ™ºèƒ½é€€é¿ç­–ç•¥ï¼šæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
                if attempt > 1:
                    base_wait = self.backoff_factor ** (attempt - 1)
                    # æ·»åŠ 10-30%çš„éšæœºæŠ–åŠ¨ï¼Œé¿å…å¤šä¸ªè¯·æ±‚åŒæ—¶é‡è¯•
                    jitter = random.uniform(0.1, 0.3)
                    wait_time = base_wait * (1 + jitter)
                    api_logger.info(f"ç­‰å¾… {wait_time:.2f} ç§’åé‡è¯• (å°è¯• {attempt}/{self.max_retries})")
                    time.sleep(wait_time)
                
                response = self._call_api(messages)
                
                # å¤„ç†ç‰¹æ®Šé”™è¯¯ç 
                if response:
                    # æå–tokenä½¿ç”¨ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                    if 'usage' in response and 'total_tokens' in response['usage']:
                        self.response_stats['total_tokens_used'] += response['usage']['total_tokens']
                    
                    if "choices" in response and len(response["choices"]) > 0:
                        content = response["choices"][0]["message"]["content"]
                        api_logger.info(f"APIè°ƒç”¨æˆåŠŸ (å°è¯• {attempt}/{self.max_retries})")
                        return content
                    else:
                        api_logger.warning(f"APIå“åº”ç¼ºå°‘choiceså­—æ®µ")
                else:
                    api_logger.warning(f"APIè¿”å›ç©ºå“åº”")
                    
            except requests.exceptions.Timeout:
                api_logger.error(f"APIè¯·æ±‚è¶…æ—¶ (å°è¯• {attempt}/{self.max_retries})")
            except requests.exceptions.ConnectionError:
                api_logger.error(f"APIè¿æ¥é”™è¯¯ (å°è¯• {attempt}/{self.max_retries})")
            except requests.exceptions.RequestException as e:
                api_logger.error(f"APIè¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt}/{self.max_retries}): {str(e)}")
            except Exception as e:
                api_logger.error(f"æœªé¢„æœŸçš„å¼‚å¸¸ (å°è¯• {attempt}/{self.max_retries}): {str(e)}")
                traceback.print_exc()
        
        api_logger.error(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({self.max_retries})")
        return None

    def _call_api_with_retry_stream(self, messages: List[Dict[str, str]]) -> Generator[str, None, None]:
        """å¸¦é‡è¯•æœºåˆ¶çš„æµå¼APIè°ƒç”¨"""
        attempt = 0
        while attempt < self.max_retries:
            attempt += 1
            try:
                logger.info(f"å¼€å§‹æµå¼APIè°ƒç”¨ (å°è¯• {attempt}/{self.max_retries})")
                # è·å–æµå¼ç”Ÿæˆå™¨
                stream_generator = self._call_api_stream(messages)
                
                # å¦‚æœç”Ÿæˆå™¨å­˜åœ¨ï¼Œåˆ™é€å—yieldå†…å®¹
                if stream_generator:
                    chunk_count = 0
                    for chunk in stream_generator:
                        if chunk:
                            yield chunk
                            chunk_count += 1
                    # å¦‚æœæˆåŠŸyieldå®Œæ‰€æœ‰å†…å®¹ï¼Œè¿”å›
                    logger.info(f"æµå¼APIè°ƒç”¨æˆåŠŸå®Œæˆ (å°è¯• {attempt}/{self.max_retries}, è¿”å›{chunk_count}ä¸ªå—)")
                    return
                
            except requests.exceptions.Timeout:
                logger.error(f"æµå¼APIè¯·æ±‚è¶…æ—¶ (å°è¯• {attempt}/{self.max_retries})")
                # å°è¯•ç”Ÿæˆä¸€ä¸ªè¶…æ—¶æç¤ºï¼Œç„¶åç»§ç»­é‡è¯•
                if attempt == 1:
                    yield "[æ­£åœ¨è¿æ¥...]"
            except requests.exceptions.ConnectionError:
                logger.error(f"æµå¼APIè¿æ¥é”™è¯¯ (å°è¯• {attempt}/{self.max_retries})")
            except requests.exceptions.RequestException as e:
                logger.error(f"æµå¼APIè¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt}/{self.max_retries}): {str(e)}")
            except Exception as e:
                logger.error(f"æµå¼APIè°ƒç”¨å¼‚å¸¸ (å°è¯• {attempt}/{self.max_retries}): {str(e)}")
                traceback.print_exc()
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…å¹¶é‡è¯•
            if attempt < self.max_retries:
                # æ™ºèƒ½é€€é¿ç­–ç•¥ï¼šæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
                base_wait = self.backoff_factor ** (attempt - 1)
                jitter = random.uniform(0.1, 0.3)
                wait_time = base_wait * (1 + jitter)
                logger.warning(f"æµå¼APIè°ƒç”¨å¤±è´¥ï¼Œ{wait_time:.2f}ç§’åé‡è¯• (å°è¯• {attempt}/{self.max_retries})")
                time.sleep(wait_time)
            else:
                logger.error(f"æµå¼APIè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({self.max_retries})")
                # æä¾›é»˜è®¤å›å¤
                yield "\nå¾ˆæŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•ä¸ºæ‚¨æä¾›è¯¥ä¿¡æ¯ã€‚è¯·ç¨åå†è¯•ã€‚"

    def validate_api_key(self) -> bool:
        """éªŒè¯ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ"""
        if not self.api_key:
            api_logger.warning("APIå¯†é’¥æœªè®¾ç½®")
            return False
        
        test_messages = [{"role": "user", "content": "è¯·è¿”å›'éªŒè¯æˆåŠŸ'ä½œä¸ºå“åº”"}]
        try:
            # ä¸´æ—¶é™ä½è¶…æ—¶æ—¶é—´ä»¥åŠ å¿«éªŒè¯
            original_timeout = self.timeout
            self.timeout = 10
            resp = self._call_api(test_messages)
            self.timeout = original_timeout
            
            # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
            if resp and "choices" in resp and len(resp["choices"]) > 0:
                content = resp["choices"][0]["message"]["content"]
                # éªŒè¯å“åº”å†…å®¹
                return "éªŒè¯æˆåŠŸ" in content or content.strip() != ""
            return False
        except Exception as e:
            api_logger.error(f"APIå¯†é’¥éªŒè¯å¤±è´¥: {str(e)}")
            # æ¢å¤åŸå§‹è¶…æ—¶è®¾ç½®
            try:
                self.timeout = original_timeout
            except:
                pass
            return False

    def is_healthy(self) -> bool:
        """æ£€æŸ¥APIæœåŠ¡æ˜¯å¦å¥åº·"""
        return self._is_healthy

    def refresh_client(self):
        """åˆ·æ–°å®¢æˆ·ç«¯å®ä¾‹ï¼Œé‡æ–°ä»å·¥å‚åˆ›å»º"""
        # é‡æ–°å¯¼å…¥æœ€æ–°çš„å…¨å±€é…ç½®ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹è®¾ç½®
        from src.config import global_config
        # åˆ›å»ºæ–°çš„å®¢æˆ·ç«¯å®ä¾‹
        new_client = LLMClientFactory.create_client(global_config)
        
        # ç›´æ¥æ›´æ–°å…¨å±€å®¢æˆ·ç«¯å®ä¾‹ï¼Œé¿å…æ¨¡å—å¯¼å…¥é—®é¢˜
        import src.llm_client
        src.llm_client.llm_client = new_client
        
        # åŒæ—¶æ›´æ–°å¯èƒ½å¼•ç”¨äº†è¯¥å®¢æˆ·ç«¯çš„å…¶ä»–æ¨¡å—
        try:
            import src.web_interface
            if hasattr(src.web_interface, 'llm_client'):
                src.web_interface.llm_client = new_client
                logger.info("å·²æˆåŠŸæ›´æ–°web_interfaceä¸­çš„å®¢æˆ·ç«¯å®ä¾‹")
        except ImportError:
            pass  # å¦‚æœweb_interfaceæ¨¡å—ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯
        
        # ç‰¹åˆ«æ›´æ–°RAGPipelineä¸­çš„å®¢æˆ·ç«¯å®ä¾‹ï¼Œå› ä¸ºå®ƒåœ¨åˆå§‹åŒ–æ—¶ä¿å­˜äº†å¯¹æ—§å®¢æˆ·ç«¯çš„å¼•ç”¨
        try:
            from src.rag_pipeline import rag_pipeline
            if hasattr(rag_pipeline, 'llm_client'):
                rag_pipeline.llm_client = new_client
                logger.info("å·²æˆåŠŸæ›´æ–°RAGPipelineä¸­çš„å®¢æˆ·ç«¯å®ä¾‹")
        except ImportError:
            pass  # å¦‚æœrag_pipelineæ¨¡å—ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯
        
        # ç‰¹åˆ«æ›´æ–°AdaptiveRAGPipelineä¸­çš„å®¢æˆ·ç«¯å®ä¾‹ï¼Œå› ä¸ºå®ƒåœ¨åˆå§‹åŒ–æ—¶ä¹Ÿä¿å­˜äº†å¯¹æ—§å®¢æˆ·ç«¯çš„å¼•ç”¨
        try:
            from src.adaptive_rag_pipeline import adaptive_rag_pipeline
            if hasattr(adaptive_rag_pipeline, 'llm_client'):
                adaptive_rag_pipeline.llm_client = new_client
                logger.info("å·²æˆåŠŸæ›´æ–°AdaptiveRAGPipelineä¸­çš„å®¢æˆ·ç«¯å®ä¾‹")
        except ImportError:
            pass  # å¦‚æœadaptive_rag_pipelineæ¨¡å—ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯
            
        # ç‰¹åˆ«æ›´æ–°Agentä¸­çš„å®¢æˆ·ç«¯å®ä¾‹ï¼Œå› ä¸ºå®ƒä¹Ÿéœ€è¦ä½¿ç”¨æœ€æ–°çš„LLMå®¢æˆ·ç«¯
        try:
            from src.agent import agent
            if hasattr(agent, 'llm_client'):
                agent.llm_client = new_client
                logger.info("å·²æˆåŠŸæ›´æ–°Agentä¸­çš„å®¢æˆ·ç«¯å®ä¾‹")
        except ImportError:
            pass  # å¦‚æœagentæ¨¡å—ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯
        
        logger.info(f"å®¢æˆ·ç«¯å·²åˆ·æ–°: æ–°æä¾›å•†={new_client.provider}, æ–°æ¨¡å‹={new_client.model_name}")
        
        # è¿”å›æ–°çš„å®¢æˆ·ç«¯å®ä¾‹ï¼Œä»¥ä¾¿è°ƒç”¨è€…å¯ä»¥ç›´æ¥ä½¿ç”¨
        return new_client

    def _call_api(self, messages: List[Dict[str, str]]) -> Optional[Dict[str, Any]]:
        """æ‰§è¡Œå®é™…çš„APIè°ƒç”¨"""
        try:
            # åœ¨è°ƒç”¨æ¨¡å‹å‰æ‰“å°æ—¥å¿—ï¼Œæ˜¾ç¤ºä½¿ç”¨çš„æ¨¡å‹å’Œæ¨¡å‹keyçš„é…ç½®æƒ…å†µ
            api_logger.info(f"å‡†å¤‡è°ƒç”¨æ¨¡å‹ - æä¾›å•†: {self.provider}, æ¨¡å‹åç§°: {self.model_name}")
            api_logger.info(f"APIå¯†é’¥çŠ¶æ€: {'å·²é…ç½®' if self.api_key else 'æœªé…ç½®'}")
            
            # ä½¿ç”¨è´Ÿè½½å‡è¡¡è·å–URL
            url = self._get_next_api_url()
            headers = self._get_headers()
            payload = self._build_payload(messages, stream=False)
            
            # æ•æ„Ÿä¿¡æ¯å±è”½
            sanitized_payload = payload.copy()
            if 'messages' in sanitized_payload:
                sanitized_payload['messages'] = [
                    {k: '(å†…å®¹å·²å±è”½)' if k == 'content' else v for k, v in msg.items()}
                    for msg in sanitized_payload['messages']
                ]
            
            api_logger.debug(f"APIè°ƒç”¨: URL={url}, æ¶ˆæ¯æ•°é‡={len(messages)}")
            api_logger.debug(f"è¯·æ±‚å‚æ•°: {json.dumps(sanitized_payload, ensure_ascii=False, indent=2)}")
            
            # å‘é€è¯·æ±‚
            response = self.session.post(
                url, 
                headers=headers, 
                json=payload, 
                timeout=self.timeout
            )
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 429:
                # é€Ÿç‡é™åˆ¶å¤„ç†
                api_logger.warning(f"APIé€Ÿç‡é™åˆ¶: çŠ¶æ€ç  {response.status_code}")
                # æ£€æŸ¥æ˜¯å¦æœ‰Retry-Afterå¤´éƒ¨
                retry_after = response.headers.get('Retry-After')
                if retry_after:
                    wait_time = int(retry_after)
                    api_logger.info(f"æ ¹æ®Retry-Afterå¤´éƒ¨ï¼Œç­‰å¾… {wait_time} ç§’")
                    time.sleep(wait_time)
                return None
            elif response.status_code == 401:
                # è®¤è¯é”™è¯¯
                api_logger.error(f"APIè®¤è¯é”™è¯¯: çŠ¶æ€ç  {response.status_code}")
                api_logger.error(f"è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
                return None
            elif response.status_code >= 500:
                # æœåŠ¡å™¨é”™è¯¯
                api_logger.error(f"APIæœåŠ¡å™¨é”™è¯¯: çŠ¶æ€ç  {response.status_code}")
                api_logger.error(f"å“åº”å†…å®¹: {response.text[:500]}..." if len(response.text) > 500 else response.text)
                return None
            else:
                api_logger.error(f"APIè°ƒç”¨å¤±è´¥: çŠ¶æ€ç  {response.status_code}")
                api_logger.error(f"å“åº”å†…å®¹: {response.text[:500]}..." if len(response.text) > 500 else response.text)
                return None
        except requests.exceptions.Timeout:
            api_logger.error(f"APIè¯·æ±‚è¶…æ—¶")
            raise
        except requests.exceptions.ConnectionError:
            api_logger.error(f"APIè¿æ¥é”™è¯¯")
            raise
        except Exception as e:
            api_logger.error(f"APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            traceback.print_exc()
            raise
        return None

    def _call_api_stream(self, messages: List[Dict[str, str]]) -> Generator[str, None, None]:
        """æ‰§è¡Œæµå¼APIè°ƒç”¨ï¼Œæ”¯æŒæ›´å¥å£®çš„æµå¼å“åº”å¤„ç†"""
        try:
            url = self._get_api_url()
            headers = self._get_headers()
            payload = self._build_payload(messages, stream=True)
            
            logger.debug(f"æµå¼APIè°ƒç”¨: URL={url}, æ¶ˆæ¯æ•°é‡={len(messages)}")
            
            # å‘é€æµå¼è¯·æ±‚
            with self.session.post(
                url, 
                headers=headers, 
                json=payload, 
                stream=True, 
                timeout=self.timeout
            ) as response:
                if response.status_code == 200:
                    # å¤„ç†æµå¼å“åº”
                    buffer = ""
                    for chunk in response.iter_lines():
                        if chunk:
                            # ç§»é™¤ 'data: ' å‰ç¼€å¹¶è§£æJSON
                            try:
                                chunk_str = chunk.decode('utf-8')
                                # å¤„ç†å¯èƒ½çš„å¤šä¸ªæ•°æ®å—
                                parts = chunk_str.split('data: ')
                                for part in parts:
                                    part = part.strip()
                                    if part and part != '[DONE]':
                                        try:
                                            data = json.loads(part)
                                            if 'choices' in data and data['choices']:
                                                delta = data['choices'][0].get('delta', {})
                                                if 'content' in delta:
                                                    # ä½¿ç”¨æ›´å¤§çš„å—æ¥ä¼˜åŒ–è¾“å‡ºæµ
                                                    buffer += delta['content']
                                                    if len(buffer) >= getattr(self.config, 'STREAMING_CHUNK_SIZE', 50):
                                                        yield buffer
                                                        buffer = ""
                                        except json.JSONDecodeError:
                                            logger.warning(f"æ— æ³•è§£ææµå¼å“åº”å—: {part}")
                                
                                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æµçš„æœ«å°¾
                                if chunk_str.strip() == '[DONE]':
                                    # è¾“å‡ºç¼“å†²åŒºä¸­çš„å‰©ä½™å†…å®¹
                                    if buffer:
                                        yield buffer
                                    break
                            except Exception as e:
                                logger.warning(f"å¤„ç†æµå¼å“åº”å—æ—¶å‡ºé”™: {str(e)}")
                    
                    # ç¡®ä¿ç¼“å†²åŒºä¸­çš„æ‰€æœ‰å†…å®¹éƒ½è¢«è¾“å‡º
                    if buffer:
                        yield buffer
                    
                    # è¾“å‡ºä¸€ä¸ªç©ºå­—ç¬¦ä¸²ä»¥ç¡®ä¿æµçš„æ­£ç¡®ç»“æŸ
                    yield ""
                    
                elif response.status_code == 429:
                    # é€Ÿç‡é™åˆ¶å¤„ç†
                    logger.warning(f"æµå¼APIé€Ÿç‡é™åˆ¶: çŠ¶æ€ç  {response.status_code}")
                    yield "[ç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åå†è¯•]"
                elif response.status_code == 401:
                    # è®¤è¯é”™è¯¯
                    logger.error(f"æµå¼APIè®¤è¯é”™è¯¯: çŠ¶æ€ç  {response.status_code}")
                    yield "[è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥]"
                else:
                    logger.error(f"æµå¼APIè°ƒç”¨å¤±è´¥: çŠ¶æ€ç  {response.status_code}")
                    logger.error(f"å“åº”å†…å®¹: {response.text[:500]}..." if len(response.text) > 500 else response.text)
                    yield "[APIè°ƒç”¨å¤±è´¥]"
        except requests.exceptions.Timeout:
            logger.error(f"æµå¼APIè¯·æ±‚è¶…æ—¶")
            raise
        except requests.exceptions.ConnectionError:
            logger.error(f"æµå¼APIè¿æ¥é”™è¯¯")
            raise
        except Exception as e:
            logger.error(f"æµå¼APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            traceback.print_exc()
            raise

# ========================
# ğŸš€ DeepSeek å®¢æˆ·ç«¯å®ç°
# ========================
class DeepSeekClient(BaseLLMClient):
    def _get_headers(self) -> Dict[str, str]:
        return {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "Connection": "close",
            "Authorization": f"Bearer {self.api_key}"
        }

    def _get_api_url(self) -> str:
        return getattr(self.config, 'MODEL_URL', "https://api.deepseek.com/v1/chat/completions")

    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:
        return {
            "model": self.model_name,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "stream": stream
        }


# ========================
# ğŸ§© OpenAI / å…¼å®¹å®¢æˆ·ç«¯
# ========================
class OpenAIClient(BaseLLMClient):
    def _get_headers(self) -> Dict[str, str]:
        return {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "Connection": "close",
            "Authorization": f"Bearer {self.api_key}"
        }

    def _get_api_url(self) -> str:
        return getattr(self.config, 'MODEL_URL', "https://api.openai.com/v1/chat/completions")

    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:
        return {
            "model": self.model_name,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "stream": stream
        }


# ========================
# ğŸŒ™ Moonshot (æœˆä¹‹æš—é¢) å®¢æˆ·ç«¯
# ========================
class MoonshotClient(BaseLLMClient):
    def _get_headers(self) -> Dict[str, str]:
        return {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "Connection": "close",
            "Authorization": f"Bearer {self.api_key}"
        }

    def _get_api_url(self) -> str:
        return getattr(self.config, 'MODEL_URL', "https://api.moonshot.cn/v1/chat/completions")

    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:
        return {
            "model": self.model_name,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "stream": stream
        }

# ========================
# ğŸ¯ Qwen (é€šä¹‰åƒé—®) HTTPå®¢æˆ·ç«¯ â€”â€” æœ€ç»ˆä¿®å¤ç‰ˆ
# ========================
class QwenClient(BaseLLMClient):

    def __init__(self, config=None):
        # ç¡®ä¿ä½¿ç”¨ä¼ å…¥çš„é…ç½®ï¼Œä¸ä½¿ç”¨é»˜è®¤å‚æ•°ä»¥é¿å…å¼•ç”¨æ—§é…ç½®
        if config is None:
            from src.config import global_config
            config = global_config
            
        super().__init__(config)
        
        # çˆ¶ç±»å·²ç»å¤„ç†äº†APIå¯†é’¥çš„è·å–ï¼Œä½†æˆ‘ä»¬å†ç¡®è®¤ä¸€æ¬¡
        if not self.api_key:
            logger.warning("æœªè®¾ç½® QWEN_API_KEYï¼Œè°ƒç”¨å¯èƒ½å¤±è´¥ï¼")

    
    def _get_headers(self) -> Dict[str, str]:
        return {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "Connection": "close",
            "Authorization": f"Bearer {self.api_key}"
        }

    
    def _get_api_url(self) -> str:

        # ä½¿ç”¨ DashScope å…¼å®¹ OpenAI çš„æ¥å£

        return getattr(self.config, 'MODEL_URL', "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions")

    
    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:

        # ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼

        return {

            "model": self.model_name,  # å¦‚ "qwen-plus", "qwen-turbo", "qwen-max"

            "messages": messages,

            "temperature": self.temperature,

            "max_tokens": self.max_tokens,

            "stream": stream

        }

# ========================
# ğŸ¯ å·¥å‚ç±»ï¼šæ ¹æ®é…ç½®åˆ›å»ºå®¢æˆ·ç«¯
# ========================
class LLMClientFactory:
    @staticmethod
    def create_client(config=None) -> BaseLLMClient:
        config = config or global_config
        provider = config.MODEL_PROVIDER.lower()

        client_map = {
            "deepseek": DeepSeekClient,
            "openai": OpenAIClient,
            "moonshot": MoonshotClient,
            "qwen": QwenClient,
            # "qwen_dashscope": QwenDashScopeClient,  # æš‚æœªå®ç°
            # å¯ç»§ç»­æ‰©å±•
        }

        if provider in client_map:
            return client_map[provider](config)
        else:
            logger.warning(f"æœªçŸ¥æ¨¡å‹æä¾›å•†: {provider}ï¼Œé»˜è®¤ä½¿ç”¨ DeepSeekClient")
            return DeepSeekClient(config)

# åˆ›å»ºLLMå®¢æˆ·ç«¯å®ä¾‹
llm_client = LLMClientFactory.create_client()

# ========================
# ğŸ”„ å…¨å±€åˆ·æ–°å‡½æ•°ï¼ˆæä¾›ç»™å…¶ä»–æ¨¡å—è°ƒç”¨ï¼‰
# ========================
def refresh_client(target_module: Optional[str] = None, config=None) -> bool:
    """å…¨å±€åˆ·æ–°LLMå®¢æˆ·ç«¯å®ä¾‹å¹¶åŒæ­¥åˆ°ç›¸å…³æ¨¡å—ã€‚

    å…¼å®¹ä¸åŒè°ƒç”¨æ–¹å¼ï¼Œä¾‹å¦‚åœ¨ web_interface æˆ– agent ä¸­ç›´æ¥è°ƒç”¨ã€‚
    å¯å¿½ç•¥ä¼ å…¥å‚æ•°ï¼Œä»…ç”¨äºç»Ÿä¸€æ¥å£ï¼Œé¿å… NameErrorã€‚
    """
    try:
        # ä¼˜å…ˆä½¿ç”¨å®ä¾‹æ–¹æ³•çš„åˆ·æ–°é€»è¾‘ï¼Œå·²åŒ…å«æ¨¡å—åŒæ­¥æ›´æ–°
        try:
            llm_client.refresh_client()
            return True
        except Exception:
            # å›é€€æ–¹æ¡ˆï¼šæ‰‹åŠ¨åˆ›å»ºå¹¶æ›¿æ¢å…¨å±€å®¢æˆ·ç«¯ï¼Œå†åŒæ­¥åˆ°ç›¸å…³æ¨¡å—
            from src.config import global_config as _global_config
            new_client = LLMClientFactory.create_client(config or _global_config)

            import src.llm_client as _lc
            _lc.llm_client = new_client

            # åŒæ­¥æ›´æ–° web_interface
            try:
                import src.web_interface as _wi
                if hasattr(_wi, 'llm_client'):
                    _wi.llm_client = new_client
            except Exception:
                pass

            # åŒæ­¥æ›´æ–° rag_pipeline
            try:
                from src.rag_pipeline import rag_pipeline as _rp
                if hasattr(_rp, 'llm_client'):
                    _rp.llm_client = new_client
            except Exception:
                pass

            # åŒæ­¥æ›´æ–° adaptive_rag_pipeline
            try:
                from src.adaptive_rag_pipeline import adaptive_rag_pipeline as _arp
                if hasattr(_arp, 'llm_client'):
                    _arp.llm_client = new_client
            except Exception:
                pass

            # åŒæ­¥æ›´æ–° agent
            try:
                from src.agent import agent as _agent
                if hasattr(_agent, 'llm_client'):
                    _agent.llm_client = new_client
            except Exception:
                pass

            return True
    except Exception as e:
        logger.error(f"åˆ·æ–°LLMå®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
        return False