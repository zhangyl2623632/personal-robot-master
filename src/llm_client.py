# llm_client.py
# é€šç”¨å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ”¯æŒ DeepSeek / OpenAI / Qwen / Moonshot / SparkDesk ç­‰
# æ”¯æŒä¸¥æ ¼æ¨¡å¼ã€ç»“æ„åŒ–è¾“å‡ºã€å…ƒæ•°æ®å¢å¼ºã€æ„å›¾è¯†åˆ«

import os
import re
import logging
import requests
import json
from typing import List, Dict, Any, Optional, Union
from abc import ABC, abstractmethod
from dataclasses import dataclass
from enum import Enum

# å‡è®¾ä½ æœ‰ä¸€ä¸ª config æ¨¡å—ï¼Œè‹¥æ²¡æœ‰ï¼Œå¯æ›¿æ¢ä¸º dotenv æˆ–ç¡¬ç¼–ç 
try:
    from src.config import global_config
except ImportError:
    # å¦‚æœæ²¡æœ‰ configï¼Œæä¾›é»˜è®¤é…ç½®ï¼ˆä½ å¯è‡ªè¡Œä¿®æ”¹ï¼‰
    class MockConfig:
        MODEL_PROVIDER = "deepseek"  # å¯é€‰: deepseek, openai, qwen, moonshot, spark
        MODEL_NAME = "deepseek-chat"
        MODEL_URL = "https://api.deepseek.com/v1/chat/completions"
        API_KEY = os.getenv("DEEPSEEK_API_KEY") or "sk-xxx"
        TEMPERATURE = 0.1
        MAX_TOKENS = 2048
        TIMEOUT = 30
    global_config = MockConfig()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# ========================
# ğŸ§  æ™ºèƒ½ä¸¥æ ¼æ¨¡å¼ç³»ç»Ÿæç¤ºè¯ï¼ˆå¢å¼ºç‰ˆï¼‰
# ========================
STRICT_SMART_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹ï¼Œå¿…é¡»ä¸¥æ ¼ä¾æ®æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚

## æ™ºèƒ½é—®é¢˜åˆ†ç±»ä¸å“åº”ç­–ç•¥
1. **æ¦‚è¿°ç±»é—®é¢˜**ï¼ˆè®²è¿°/ä»‹ç»/æ¦‚è¿°/æ€»ç»“/ä¸»è¦å†…å®¹ï¼‰ï¼š
   - æ‰§è¡Œå…¨é¢ç»“æ„åŒ–æ¦‚æ‹¬ï¼ŒåŒ…å«æ–‡æ¡£æ‰€æœ‰å…³é”®ç»´åº¦ã€‚
   - éµå¾ªæŒ‡å®šæ ¼å¼å’Œç« èŠ‚é¡ºåºï¼Œä¸é—æ¼é‡è¦ä¿¡æ¯ã€‚
   - è¯¦ç»†æè¿°ä¸»è¦åŠŸèƒ½ã€ç›®çš„å’Œæ ¸å¿ƒå†…å®¹ã€‚
   - åˆ—å‡ºæ–‡æ¡£çš„ä¸»è¦ç« èŠ‚ã€‚
   - ç¡®ä¿å›ç­”é€»è¾‘æ¸…æ™°ã€å±‚æ¬¡åˆ†æ˜ã€‚

2. **ç»†èŠ‚ç±»é—®é¢˜**ï¼ˆå…·ä½“æ•°æ®/æµç¨‹/è§„åˆ™/é…ç½®ï¼‰ï¼š
   - ç²¾å‡†å®šä½å¹¶æå–ä¸Šä¸‹æ–‡ç›¸å…³ä¿¡æ¯ã€‚
   - å¯¹äºè¡¨æ ¼æ•°æ®ï¼Œä¿æŒåŸç»“æ„å®Œæ•´è¿˜åŸã€‚
   - å¯¹äºæµç¨‹æ­¥éª¤ï¼Œä½¿ç”¨æ•°å­—åˆ—è¡¨æ¸…æ™°å‘ˆç°ã€‚
   - å¯¹äºæŠ€æœ¯å‚æ•°ï¼Œå‡†ç¡®å¼•ç”¨åŸæ–‡æœ¯è¯­å’Œæ•°å€¼ã€‚

3. **æ— ç›¸å…³ä¿¡æ¯**ï¼š
   - ç›´æ¥å›ç­”ï¼š"æ ¹æ®ç°æœ‰èµ„æ–™ï¼Œæ— æ³•å›ç­”è¯¥é—®é¢˜ã€‚"
   - ä¸å°è¯•ç¼–é€ æˆ–çŒœæµ‹ä»»ä½•å†…å®¹ã€‚

## å¼ºåˆ¶å›ç­”æ ¼å¼è§„èŒƒ
- **å¿…é¡»ä½¿ç”¨ Markdown æ ¼å¼**ï¼Œç¡®ä¿å±‚æ¬¡æ¸…æ™°ã€‚
- **å¿…é¡»åŒ…å«ä»¥ä¸‹ç« èŠ‚**ï¼ˆè‹¥ä¸Šä¸‹æ–‡å­˜åœ¨å¯¹åº”ä¿¡æ¯ï¼‰ï¼š
  - ### ğŸ“„ æ–‡æ¡£åŸºæœ¬ä¿¡æ¯
    - åŒ…å«æ ‡é¢˜ã€ç‰ˆæœ¬ã€æ—¥æœŸã€ä½œè€…ã€äº§å“ç ç­‰å…ƒæ•°æ®ã€‚
    - æ¯ä¸ªä¿¡æ¯é¡¹ä½¿ç”¨ç‹¬ç«‹è¡Œå‘ˆç°ï¼Œä¾¿äºé˜…è¯»ã€‚
    
  - ### ğŸ¯ ç›®çš„ä¸èŒƒå›´
    - æ˜ç¡®æ–‡æ¡£çš„ä¸»è¦ç›®æ ‡å’Œé€‚ç”¨åœºæ™¯ã€‚
    - è¯¦ç»†è¯´æ˜æ–‡æ¡£çš„æ ¸å¿ƒç”¨é€”å’Œè¦†ç›–èŒƒå›´ã€‚
    
  - ### ğŸ“± æ ¸å¿ƒåŠŸèƒ½ / ç”¨æˆ·å¯è§è¡Œä¸º
    - è¯¦ç»†æè¿°æ–‡æ¡£ä¸­å®šä¹‰çš„ä¸»è¦åŠŸèƒ½ã€‚
    - åˆ—å‡ºç”¨æˆ·å¯æ„ŸçŸ¥çš„å…·ä½“æ“ä½œå’Œäº¤äº’è¡Œä¸ºã€‚
    
  - ### âš™ï¸ åç«¯é…ç½® / ç³»ç»Ÿè¦æ±‚
    - è¯´æ˜ç³»ç»Ÿé…ç½®å‚æ•°ã€ä¾èµ–é¡¹å’Œç¯å¢ƒè¦æ±‚ã€‚
    - å¼•ç”¨æŠ€æœ¯è§„èŒƒå’Œå®ç°ç»†èŠ‚ã€‚
    
  - ### ğŸ“Š æ•°æ®ç»“æ„ / è´¹ç”¨è¡¨æ ¼
    - å®Œæ•´è¿˜åŸä¸Šä¸‹æ–‡åŒ…å«çš„æ‰€æœ‰è¡¨æ ¼ã€‚
    - ä¿æŒè¡¨å¤´ã€è¡Œåˆ—å…³ç³»å’Œæ•°æ®çš„å‡†ç¡®æ€§ã€‚
    - è‹¥æœ‰å¤šä¸ªè¡¨æ ¼ï¼Œåˆ†åˆ«æ ‡è®°åºå·å’Œåç§°ã€‚
    
  - ### âœ… æ€»ç»“
    - ç®€æ˜æ‰¼è¦åœ°æ€»ç»“æ–‡æ¡£æ ¸å¿ƒä»·å€¼å’Œä¸»è¦å†…å®¹ã€‚
    - çªå‡ºæ–‡æ¡£çš„å…³é”®è¦ç‚¹å’Œåº”ç”¨å‰æ™¯ã€‚

- **ç¦æ­¢ä½¿ç”¨**ï¼š
  - ç¼–é€ ä¸Šä¸‹æ–‡æœªæåŠçš„ç»†èŠ‚ã€‚
  - ä½¿ç”¨æ¨¡ç³Šä¸æ¸…çš„æªè¾ï¼ˆå¦‚"å¯èƒ½"ã€"å¤§æ¦‚"ï¼‰ã€‚
  - è„±ç¦»ä¸Šä¸‹æ–‡è¿›è¡Œè‡ªç”±å‘æŒ¥æˆ–ä¸»è§‚åˆ¤æ–­ã€‚
  
- **è¯­è¨€é£æ ¼**ï¼š
  - ä¸“ä¸šã€å‡†ç¡®ã€ç®€æ´ã€‚
  - ä½¿ç”¨é¡¹ç›®ç¬¦å·ï¼ˆ-ï¼‰æˆ–è¡¨æ ¼ï¼ˆ|---|ï¼‰ç»„ç»‡å†…å®¹ã€‚
  - ç¡®ä¿æœ¯è¯­ç»Ÿä¸€ï¼Œä¸åŸæ–‡ä¿æŒä¸€è‡´ã€‚

è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸Šè¦æ±‚ï¼Œå¼€å§‹ä½ çš„å›ç­”ï¼š"""


# ========================
# ğŸ§© æŸ¥è¯¢é¢„å¤„ç†ï¼šè¯†åˆ«â€œè®²è¿°/æ¦‚è¿°â€æ„å›¾
# ========================
def preprocess_query(query: str) -> str:
    """é¢„å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œå°†ä¸åŒç±»å‹é—®é¢˜è½¬åŒ–ä¸ºç»“æ„åŒ–æŒ‡ä»¤"""
    if not isinstance(query, str):
        return query

    # è½¬æ¢ä¸ºå°å†™ä»¥è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„åŒ¹é…
    query_lower = query.lower()
    
    # 1. æ¦‚è¿°ç±»é—®é¢˜ - å¢å¼ºç»“æ„åŒ–æŒ‡ä»¤
    overview_triggers = [
        "è®²è¿°", "ä»‹ç»", "æ¦‚è¿°", "æ€»ç»“", "ä¸»è¦å†…å®¹", "æ˜¯ä»€ä¹ˆ", "è®²ä»€ä¹ˆ",
        "ä»‹ç»ä¸€ä¸‹", "è¯´è¯´", "ç®€è¿°", "æ–‡æ¡£å†…å®¹", "è¿™ä»½æ–‡ä»¶", "è¿™ä¸ªèµ„æ–™",
        "describe", "summary", "overview", "what is", "explain"
    ]
    
    if any(trigger in query_lower for trigger in overview_triggers):
        return "è¯·æ ¹æ®ä¸Šä¸‹æ–‡ï¼Œè¯¦ç»†ç»“æ„åŒ–æ¦‚è¿°æœ¬æ–‡æ¡£ï¼Œå¿…é¡»åŒ…å«ï¼šæ–‡æ¡£åŸºæœ¬ä¿¡æ¯ã€ç›®çš„ä¸èŒƒå›´ã€æ ¸å¿ƒåŠŸèƒ½ã€åç«¯é…ç½®ã€æ•°æ®ç»“æ„ã€æ€»ç»“ï¼Œå¹¶åˆ—å‡ºä¸»è¦ç« èŠ‚ã€‚ä½¿ç”¨æ ‡é¢˜+åˆ—è¡¨/è¡¨æ ¼æ ¼å¼ï¼Œç¡®ä¿å†…å®¹è¯¦å°½å®Œæ•´ã€‚"
    
    # 2. è¡¨æ ¼ç±»é—®é¢˜ - ç‰¹æ®Šå¤„ç†è¡¨æ ¼æ•°æ®
    table_triggers = [
        "è¡¨æ ¼", "è´¹ç‡", "ä»·æ ¼", "è´¹ç”¨", "æ”¶è´¹", "æ•°æ®ç»“æ„", "å­—æ®µ",
        "table", "fee", "cost", "price", "structure", "fields"
    ]
    
    if any(trigger in query_lower for trigger in table_triggers):
        return f"è¯·æ ¹æ®ä¸Šä¸‹æ–‡ï¼Œè¯¦ç»†å›ç­”å…³äº'{query}'çš„é—®é¢˜ã€‚å¦‚æœæ¶‰åŠè¡¨æ ¼æ•°æ®ï¼Œè¯·ä½¿ç”¨Markdownè¡¨æ ¼æ ¼å¼å®Œæ•´è¿˜åŸï¼Œç¡®ä¿è¡¨å¤´å’Œæ•°æ®å‡†ç¡®æ— è¯¯ã€‚"
    
    # 3. æµç¨‹ç±»é—®é¢˜ - ç‰¹æ®Šå¤„ç†æ­¥éª¤å’Œæµç¨‹
    process_triggers = [
        "æµç¨‹", "æ­¥éª¤", "å¦‚ä½•", "æ“ä½œ", "ç”³è¯·", "å¤„ç†", "æ­¥éª¤",
        "process", "steps", "how to", "apply", "operation"
    ]
    
    if any(trigger in query_lower for trigger in process_triggers):
        return f"è¯·æ ¹æ®ä¸Šä¸‹æ–‡ï¼Œè¯¦ç»†å›ç­”å…³äº'{query}'çš„é—®é¢˜ã€‚å¦‚æœæ¶‰åŠæµç¨‹æ­¥éª¤ï¼Œè¯·ä½¿ç”¨æ•°å­—åˆ—è¡¨æ¸…æ™°å‘ˆç°æ¯ä¸ªæ­¥éª¤çš„å…·ä½“å†…å®¹å’Œè¦æ±‚ã€‚"
    
    # 4. é…ç½®ç±»é—®é¢˜ - ç‰¹æ®Šå¤„ç†é…ç½®å‚æ•°
    config_triggers = [
        "é…ç½®", "å‚æ•°", "è®¾ç½®", "ç³»ç»Ÿ", "è¦æ±‚", "ç¯å¢ƒ",
        "config", "parameter", "setting", "system", "requirement", "environment"
    ]
    
    if any(trigger in query_lower for trigger in config_triggers):
        return f"è¯·æ ¹æ®ä¸Šä¸‹æ–‡ï¼Œè¯¦ç»†å›ç­”å…³äº'{query}'çš„é—®é¢˜ã€‚ç¡®ä¿å‡†ç¡®å¼•ç”¨é…ç½®å‚æ•°ã€ç³»ç»Ÿè¦æ±‚å’ŒæŠ€æœ¯è§„èŒƒã€‚"
    
    # ä¿æŒåŸå§‹æŸ¥è¯¢ä¸å˜
    return query


# ========================
# ğŸ§  ä¸Šä¸‹æ–‡å¢å¼ºå™¨ï¼šæå–å…ƒæ•°æ® + ç« èŠ‚ + è¡¨æ ¼ç‰‡æ®µ
# ========================
def enhance_context_with_metadata(raw_text: str, max_raw_lines=20) -> str:
    """
    ä»åŸå§‹æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–å…ƒä¿¡æ¯ï¼Œå¢å¼ºä¸Šä¸‹æ–‡ï¼Œä¾¿äºæ¨¡å‹ç†è§£
    """
    if not raw_text:
        return ""

    lines = raw_text.splitlines()
    metadata = {}
    patterns = {
        'title': r'(?:æ–‡æ¡£[åç§°å]|æ ‡é¢˜|Title|Document Name|æ–‡ä»¶å)[\s:ï¼š]*(.+)',
        'version': r'(?:ç‰ˆæœ¬|Version|Ver|ä¿®è®¢ç‰ˆ)[\s:ï¼š]*([vV]?\d+\.\d+)',
        'date': r'(?:æ—¥æœŸ|Date|Release Date|å‘å¸ƒæ—¥æœŸ)[\s:ï¼š]*(\d{1,2}[\/\-å¹´æœˆ\s]*\d{1,2}[\/\-æœˆæ—¥\s]*\d{4}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥|\d{4}[\-\/]\d{1,2}[\-\/]\d{1,2})',
        'author': r'(?:ä½œè€…|Prepared by|ç¼–å†™|Author|ç¼–åˆ¶|æ’°å†™)[\s:ï¼š]*([^\n\r,ï¼Œ]+)',
        'doc_name': r'(?:Document Name|æ–‡æ¡£åç§°)[\s:ï¼š]*([^\n\r]+)',
        'purpose': r'(?:ç›®çš„|Purpose|ç›®æ ‡)[\s:ï¼š]*([^\n\rã€‚]+)',
        'scope': r'(?:èŒƒå›´|Scope|é€‚ç”¨èŒƒå›´)[\s:ï¼š]*([^\n\rã€‚]+)',
        'product_code': r'(?:äº§å“ç |Product Code|äº§å“ç¼–å·)[\s:ï¼š]*([A-Z0-9]+)',
        'main_function': r'(?:ä¸»è¦åŠŸèƒ½|æ ¸å¿ƒåŠŸèƒ½|åŠŸèƒ½æ¦‚è¿°)[\s:ï¼š]*([^\n\rã€‚]+)',
        'core_content': r'(?:æ ¸å¿ƒå†…å®¹|ä¸»è¦å†…å®¹|å†…å®¹æ¦‚è¦)[\s:ï¼š]*([^\n\rã€‚]+)',
    }

    # æ‰«æå‰50è¡Œæå–å…ƒä¿¡æ¯
    for line in lines[:50]:
        line = line.strip()
        if not line: continue
        for key, pattern in patterns.items():
            if key in metadata: continue
            match = re.search(pattern, line, re.IGNORECASE)
            if match:
                metadata[key] = match.group(1).strip()

    # å¯å‘å¼æå–ä¸»æ ‡é¢˜
    if 'title' not in metadata:
        for line in lines[:10]:
            stripped = line.strip()
            if stripped and len(stripped) > 5 and not re.search(r'^(Version|Date|Author|Release|Prepared|Document)', stripped, re.I):
                metadata['title'] = stripped
                break

    # æå–å…³é”®æ®µè½ï¼ˆåŠŸèƒ½/é…ç½®/è´¹ç”¨/æµç¨‹ï¼‰
    key_sections = {
        'main_functions': [], 
        'system_config': [], 
        'fee_structure': [], 
        'process_flow': [],
        'data_structures': []
    }
    current_section = None

    for i, line in enumerate(lines[:200]):
        stripped = line.strip()
        if not stripped: continue

        # è¯†åˆ«ç« èŠ‚æ ‡é¢˜ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
        if re.search(r'åŠŸèƒ½|Functions|Features', stripped, re.I):
            current_section = 'main_functions'
        elif re.search(r'é…ç½®|Configuration|Settings', stripped, re.I):
            current_section = 'system_config'
        elif re.search(r'è´¹ç”¨|Fee|Cost|Price|è´¹ç‡', stripped, re.I):
            current_section = 'fee_structure'
        elif re.search(r'æµç¨‹|Process|Steps|æ­¥éª¤', stripped, re.I):
            current_section = 'process_flow'
        elif re.search(r'æ•°æ®ç»“æ„|Data Structure|è¡¨æ ¼|Table', stripped, re.I):
            current_section = 'data_structures'
        elif re.match(r'^\d+\.\s*[A-Z]', stripped) or re.match(r'^[A-Z][a-z]+\s+[A-Z][a-z]+', stripped):
            current_section = None  # æ–°ç« èŠ‚å¼€å§‹

        if current_section and len(key_sections[current_section]) < 5:
            key_sections[current_section].append(stripped)

    # æå–è¡¨æ ¼ï¼ˆæœ€å¤šæå–ä¸¤ä¸ªè¡¨æ ¼ï¼Œæ¯ä¸ª10è¡Œå†…ï¼‰
    tables = []
    current_table = []
    table_start_patterns = [
        r'\|.*\|',
        r'-{3,}',
        r'Tenure|æœŸé™|Fee|è´¹ç‡|Cost|è´¹ç”¨',
        r'å¤©\s+è´¹\s+ç”¨',
        r'å­—æ®µå|Field|å‚æ•°|Parameter',
    ]
    
    for line in lines[:300]:
        line_stripped = line.strip()
        
        # æ£€æµ‹è¡¨æ ¼å¼€å§‹
        if any(re.search(p, line_stripped, re.I) for p in table_start_patterns) and not current_table:
            current_table.append(line_stripped)
        # ç»§ç»­æ”¶é›†è¡¨æ ¼å†…å®¹
        elif current_table:
            if line_stripped and not re.match(r'^[\s\-|_]+$', line_stripped):
                current_table.append(line_stripped)
            # è¡¨æ ¼ç»“æŸæ¡ä»¶
            if not line_stripped and len(current_table) > 1:
                tables.append(current_table)
                current_table = []
                if len(tables) >= 2:  # æœ€å¤šæå–ä¸¤ä¸ªè¡¨æ ¼
                    break
        # è¡¨æ ¼è¡Œæ•°é™åˆ¶
        if len(current_table) > 10:
            tables.append(current_table)
            current_table = []
            if len(tables) >= 2:
                break
    
    # å¤„ç†æœ€åä¸€ä¸ªæœªå®Œæˆçš„è¡¨æ ¼
    if current_table and len(current_table) > 1:
        tables.append(current_table)

    # æå–ä¸»è¦ç« èŠ‚
    chapters = []
    chapter_patterns = [
        r'^\d+\.\s+[^\n\r]+',  # 1. ç« èŠ‚æ ‡é¢˜
        r'^\d+\.\d+\s+[^\n\r]+',  # 1.1 å­ç« èŠ‚æ ‡é¢˜
        r'^[A-Z]\.\s+[^\n\r]+',  # A. ç« èŠ‚æ ‡é¢˜
        r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç« \s+[^\n\r]+',  # ç¬¬ä¸€ç«  ç« èŠ‚æ ‡é¢˜
        r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s+[^\n\r]+'  # ä¸€ã€ç« èŠ‚æ ‡é¢˜
    ]
    
    for line in lines[:200]:
        line_stripped = line.strip()
        if any(re.match(p, line_stripped) for p in chapter_patterns):
            chapters.append(line_stripped)
            if len(chapters) >= 10:  # æœ€å¤šæå–10ä¸ªç« èŠ‚
                break

    # æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
    parts = ["ã€å¢å¼ºå‹æ–‡æ¡£ä¸Šä¸‹æ–‡ â€”â€” ä¸“ä¸ºæ™ºèƒ½é—®ç­”ä¼˜åŒ–ã€‘"]

    # æ–‡æ¡£åŸºæœ¬ä¿¡æ¯
    if metadata:
        parts.append("\n## ğŸ“„ æ–‡æ¡£åŸºæœ¬ä¿¡æ¯")
        label_map = {
            'title': 'æ ‡é¢˜', 'version': 'ç‰ˆæœ¬', 'date': 'å‘å¸ƒæ—¥æœŸ',
            'author': 'ä½œè€…', 'doc_name': 'æ–‡æ¡£åç§°', 'product_code': 'äº§å“ç '
        }
        for key, value in metadata.items():
            if key in label_map:
                parts.append(f"- **{label_map[key]}**: {value}")

    # æ–‡æ¡£æ ¸å¿ƒä¿¡æ¯
    if any([metadata.get('purpose'), metadata.get('scope'), metadata.get('main_function'), metadata.get('core_content')]):
        parts.append("\n## ğŸ¯ ç›®çš„ä¸æ ¸å¿ƒä¿¡æ¯")
        if metadata.get('purpose'):
            parts.append(f"- **ç›®çš„**: {metadata['purpose']}")
        if metadata.get('scope'):
            parts.append(f"- **é€‚ç”¨èŒƒå›´**: {metadata['scope']}")
        if metadata.get('main_function'):
            parts.append(f"- **ä¸»è¦åŠŸèƒ½**: {metadata['main_function']}")
        if metadata.get('core_content'):
            parts.append(f"- **æ ¸å¿ƒå†…å®¹**: {metadata['core_content']}")

    # å…³é”®å†…å®¹æ‘˜è¦
    if any(key_sections.values()):
        parts.append("\n## ğŸ“‘ å…³é”®å†…å®¹æ‘˜è¦")
        if key_sections['main_functions']:
            parts.append(f"- **ä¸»è¦åŠŸèƒ½**: " + " | ".join(key_sections['main_functions'][:3]))
        if key_sections['system_config']:
            parts.append(f"- **ç³»ç»Ÿé…ç½®**: " + " | ".join(key_sections['system_config'][:3]))
        if key_sections['fee_structure']:
            parts.append(f"- **è´¹ç”¨ç»“æ„**: " + " | ".join(key_sections['fee_structure'][:3]))
        if key_sections['process_flow']:
            parts.append(f"- **æµç¨‹æ­¥éª¤**: " + " | ".join(key_sections['process_flow'][:3]))
        if key_sections['data_structures']:
            parts.append(f"- **æ•°æ®ç»“æ„**: " + " | ".join(key_sections['data_structures'][:3]))

    # è¡¨æ ¼æ•°æ®
    if tables:
        for i, table_lines in enumerate(tables):
            table_name = f"è¡¨æ ¼{i+1}: {table_lines[0][:30]}..." if len(table_lines) > 0 else f"è¡¨æ ¼{i+1}"
            parts.append(f"\n## ğŸ“Š {table_name}")
            parts.append("```\n" + "\n".join(table_lines[:10]) + "\n```")

    # ä¸»è¦ç« èŠ‚åˆ—è¡¨
    if chapters:
        parts.append("\n## ğŸ“‘ æ–‡æ¡£ä¸»è¦ç« èŠ‚")
        for i, chapter in enumerate(chapters):
            parts.append(f"- **{chapter}**")

    # åŸå§‹å†…å®¹å¼€å¤´ï¼ˆæä¾›æ›´å¤šä¸Šä¸‹æ–‡ï¼‰
    raw_snippet = "\n".join([line.strip() for line in lines[:max_raw_lines] if line.strip()])
    if raw_snippet:
        parts.append(f"\n## ğŸ“œ åŸå§‹å†…å®¹å¼€å¤´ç‰‡æ®µ")
        parts.append(raw_snippet)

    return "\n".join(parts)


# ========================
# ğŸ§­ æ¨¡å‹æä¾›å•†æ ‡è¯†
# ========================
class ModelProvider(Enum):
    DEEPSEEK = "deepseek"
    OPENAI = "openai"
    QWEN = "qwen"
    QWEN_DASHSCOPE = "qwen_dashscope"
    MOONSHOT = "moonshot"
    SPARK = "spark"  # è®¯é£æ˜Ÿç«


# ========================
# ğŸ§± æ¨¡å‹å®¢æˆ·ç«¯åŸºç±»ï¼ˆæŠ½è±¡ï¼‰
# ========================
class BaseLLMClient(ABC):
    """LLM å®¢æˆ·ç«¯æŠ½è±¡åŸºç±»"""

    def __init__(self, config=None):
        self.config = config or global_config
        self.provider = ModelProvider(self.config.MODEL_PROVIDER.lower())
        # ä½¿ç”¨getattrç¡®ä¿å³ä½¿é…ç½®é¡¹ä¸å­˜åœ¨ä¹Ÿä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        self.api_key = getattr(self.config, 'DEEPSEEK_API_KEY', None) or getattr(self.config, 'API_KEY', None)
        self.model_name = self.config.MODEL_NAME
        self.timeout = getattr(self.config, 'TIMEOUT', 30)
        self.temperature = getattr(self.config, 'TEMPERATURE', 0.1)
        self.max_tokens = getattr(self.config, 'MAX_TOKENS', 2048)

    @abstractmethod
    def _get_headers(self) -> Dict[str, str]:
        pass

    @abstractmethod
    def _get_api_url(self) -> str:
        pass

    @abstractmethod
    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:
        pass

    def generate_response(
        self,
        prompt: str,
        context: Optional[List[str]] = None,
        history: Optional[List[Dict[str, str]]] = None,
        stream: bool = False
    ) -> Union[Optional[str], Any]:  # æµå¼è¿”å›ç”Ÿæˆå™¨
        """ç”Ÿæˆå›ç­”"""
        try:
            messages = self._build_messages(prompt, context, history)
            if stream:
                return self._call_api_stream(messages)
            else:
                response = self._call_api(messages)
                if response and "choices" in response and len(response["choices"]) > 0:
                    content = response["choices"][0]["message"]["content"]
                    logger.info(f"ç”Ÿæˆå›ç­”æˆåŠŸï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
                    return content
                else:
                    logger.error(f"API å“åº”æ ¼å¼å¼‚å¸¸: {response}")
                    return None
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›ç­”å¤±è´¥: {str(e)}")
            return None

    def _build_messages(
        self,
        prompt: str,
        context: Optional[List[str]] = None,
        history: Optional[List[Dict[str, str]]] = None
    ) -> List[Dict[str, str]]:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨"""
        messages = [{"role": "system", "content": STRICT_SMART_SYSTEM_PROMPT}]

        if history:
            messages.extend(history)

        processed_query = preprocess_query(prompt)

        if context:
            enhanced_contexts = []
            for i, ctx in enumerate(context):
                enhanced_ctx = enhance_context_with_metadata(ctx)
                enhanced_contexts.append(f"ã€ä¸Šä¸‹æ–‡ {i+1}ã€‘\n{enhanced_ctx}")

            context_text = "\n\n".join(enhanced_contexts)
            user_content = f"{context_text}\n\n---\n\nã€ç”¨æˆ·é—®é¢˜ã€‘\n{processed_query}"
        else:
            user_content = processed_query

        messages.append({"role": "user", "content": user_content})
        return messages

    def _call_api(self, messages: List[Dict[str, str]]) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨ APIï¼ˆéæµå¼ï¼‰"""
        try:
            headers = self._get_headers()
            payload = self._build_payload(messages, stream=False)
            response = requests.post(
                self._get_api_url(),
                headers=headers,
                json=payload,
                timeout=self.timeout
            )
            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
                return None
        except Exception as e:
            logger.error(f"API è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return None

    def _call_api_stream(self, messages: List[Dict[str, str]]):
        """æµå¼è°ƒç”¨ï¼ˆè¿”å›ç”Ÿæˆå™¨ï¼‰"""
        try:
            headers = self._get_headers()
            payload = self._build_payload(messages, stream=True)
            response = requests.post(
                self._get_api_url(),
                headers=headers,
                json=payload,
                stream=True,
                timeout=self.timeout
            )
            if response.status_code != 200:
                logger.error(f"æµå¼APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return

            for line in response.iter_lines():
                if line:
                    decoded = line.decode('utf-8')
                    if decoded.startswith("data: "):
                        decoded = decoded[6:]
                    if decoded == "[DONE]":
                        break
                    try:
                        chunk = json.loads(decoded)
                        if "choices" in chunk and len(chunk["choices"]) > 0:
                            delta = chunk["choices"][0].get("delta", {})
                            content = delta.get("content", "")
                            if content:
                                yield content
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            logger.error(f"æµå¼è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return

    def validate_api_key(self) -> bool:
        """éªŒè¯ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ"""
        if not self.api_key:
            return False
        test_messages = [{"role": "user", "content": "Hello"}]
        try:
            resp = self._call_api(test_messages)
            return resp is not None
        except Exception:
            return False


# ========================
# ğŸš€ DeepSeek å®¢æˆ·ç«¯å®ç°
# ========================
class DeepSeekClient(BaseLLMClient):
    def _get_headers(self) -> Dict[str, str]:
        return {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

    def _get_api_url(self) -> str:
        return getattr(self.config, 'MODEL_URL', "https://api.deepseek.com/v1/chat/completions")

    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:
        return {
            "model": self.model_name,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "stream": stream
        }


# ========================
# ğŸ§© OpenAI / å…¼å®¹å®¢æˆ·ç«¯
# ========================
class OpenAIClient(BaseLLMClient):
    def _get_headers(self) -> Dict[str, str]:
        return {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

    def _get_api_url(self) -> str:
        return getattr(self.config, 'MODEL_URL', "https://api.openai.com/v1/chat/completions")

    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:
        return {
            "model": self.model_name,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "stream": stream
        }


# ========================
# ğŸŒ™ Moonshot (æœˆä¹‹æš—é¢) å®¢æˆ·ç«¯
# ========================
class MoonshotClient(BaseLLMClient):
    def _get_headers(self) -> Dict[str, str]:
        return {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

    def _get_api_url(self) -> str:
        return getattr(self.config, 'MODEL_URL', "https://api.moonshot.cn/v1/chat/completions")

    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:
        return {
            "model": self.model_name,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "stream": stream
        }

# ========================# ğŸ¯ Qwen (é€šä¹‰åƒé—®) HTTPå®¢æˆ·ç«¯# ========================class QwenClient(BaseLLMClient):    def __init__(self, config=None):        super().__init__(config)        # è®¾ç½®APIå¯†é’¥        if hasattr(self.config, 'DASHSCOPE_API_KEY') and self.config.DASHSCOPE_API_KEY:            self.api_key = self.config.DASHSCOPE_API_KEY        elif hasattr(self.config, 'QWEN_API_KEY') and self.config.QWEN_API_KEY:            self.api_key = self.config.QWEN_API_KEY        else:            # å°è¯•ä»ç¯å¢ƒå˜é‡ä¸­è·å–APIå¯†é’¥            import os            api_key = os.getenv('DASHSCOPE_API_KEY') or os.getenv('QWEN_API_KEY')            if api_key:                self.api_key = api_key            else:                logger.warning("æœªè®¾ç½®DASHSCOPE_API_KEYæˆ–QWEN_API_KEY")    
class QwenDashScopeClient(BaseLLMClient):
    def __init__(self, config=None):
        super().__init__(config)
        # è®¾ç½®APIå¯†é’¥
        if hasattr(self.config, 'DASHSCOPE_API_KEY') and self.config.DASHSCOPE_API_KEY:
            self.api_key = self.config.DASHSCOPE_API_KEY
        elif hasattr(self.config, 'QWEN_API_KEY') and self.config.QWEN_API_KEY:
            self.api_key = self.config.QWEN_API_KEY
        else:
            # å°è¯•ä»ç¯å¢ƒå˜é‡ä¸­è·å–APIå¯†é’¥
            import os
            api_key = os.getenv('DASHSCOPE_API_KEY') or os.getenv('QWEN_API_KEY')
            if api_key:
                self.api_key = api_key
            else:
                logger.warning("æœªè®¾ç½®DASHSCOPE_API_KEYæˆ–QWEN_API_KEY")
    def _get_headers(self) -> Dict[str, str]:
        return {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
            "X-DashScope-SSE": "enable"  # å¦‚æœéœ€è¦æµå¼å“åº”ï¼Œå¯åŠ æ­¤å¤´ï¼ˆDashScope æ”¯æŒï¼‰
        }

    def _get_api_url(self) -> str:
        # é˜¿é‡Œäº‘ DashScope API åœ°å€ï¼ˆQwen ç³»åˆ—ï¼‰
        # å¿½ç•¥é…ç½®ä¸­çš„ç©ºURLï¼Œç›´æ¥è¿”å›é»˜è®¤URL
        return 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation'

    def _build_payload(self, messages: List[Dict[str, str]], stream: bool = False) -> Dict[str, Any]:
        return {
            "model": self.model_name,  # ä¾‹å¦‚ï¼šqwen-plus
            "input": {
                "messages": messages
            },
            "parameters": {
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
                "result_format": "message"  # DashScope æ¨èæ ¼å¼
            },
            "stream": stream
        }
        
    def _call_api(self, messages: List[Dict[str, str]]) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨ APIï¼ˆéæµå¼ï¼‰"""
        try:
            url = self._get_api_url()
            headers = self._get_headers()
            payload = self._build_payload(messages, stream=False)
            
            logger.debug(f"[QWEN_API] å‡†å¤‡å‘é€è¯·æ±‚åˆ° {url}")
            logger.debug(f"[QWEN_API] è¯·æ±‚å¤´: {headers}")
            logger.debug(f"[QWEN_API] è¯·æ±‚ä½“: {payload}")
            
            response = requests.post(
                url,
                headers=headers,
                json=payload,
                stream=True,
                timeout=self.timeout
            )
            
            logger.debug(f"[QWEN_API] å“åº”çŠ¶æ€ç : {response.status_code}")
            logger.debug(f"[QWEN_API] å“åº”å¤´: {dict(response.headers)}")
            
            if response.status_code == 200:
                logger.debug(f"[QWEN_API] APIè°ƒç”¨æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")
                
                # åˆå§‹åŒ–å˜é‡
                complete_content = ""
                all_lines = []
                
                # å³ä½¿æ˜¯éæµå¼è°ƒç”¨ï¼ŒQwen DashScope API ä¹Ÿè¿”å›äº‹ä»¶æµæ ¼å¼
                logger.debug("[QWEN_API] å¼€å§‹å¤„ç†å“åº”æµ...")
                
                # ç›´æ¥è·å–æ•´ä¸ªå“åº”æ–‡æœ¬ï¼Œç„¶åæŒ‰è¡Œå¤„ç†
                raw_response = response.text
                logger.debug(f"[QWEN_API] åŸå§‹å“åº”æ–‡æœ¬é•¿åº¦: {len(raw_response)} å­—ç¬¦")
                
                # æŒ‰è¡Œåˆ†å‰²
                lines = raw_response.split('\n')
                for i, line in enumerate(lines):
                    line = line.strip()
                    if not line:
                        continue
                        
                    all_lines.append(line)
                    logger.debug(f"[QWEN_API] å¤„ç†è¡Œ {i+1}: {line}")
                    
                    # å¤„ç†æ•°æ®è¡Œ - æ³¨æ„è¿™é‡Œç”¨startswith('data:')è€Œä¸æ˜¯'data: '
                    if line.startswith('data:'):
                        try:
                            # æå–æ•°æ®éƒ¨åˆ†ï¼Œä½¿ç”¨æ­£ç¡®çš„åˆ‡ç‰‡å’Œstrip()å¤„ç†
                            data_part = line[5:].strip()
                            logger.debug(f"[QWEN_API] æ•°æ®éƒ¨åˆ†: {data_part}")
                            
                            chunk = json.loads(data_part)
                            logger.debug(f"[QWEN_API] è§£æåˆ°æ•°æ®å—: {chunk}")
                            
                            # æå–å†…å®¹
                            if ('output' in chunk and 
                                'choices' in chunk['output'] and 
                                isinstance(chunk['output']['choices'], list) and 
                                len(chunk['output']['choices']) > 0):
                                choice = chunk['output']['choices'][0]
                                if ('message' in choice and 
                                    'content' in choice['message']):
                                    content = choice['message']['content']
                                    logger.debug(f"[QWEN_API] æå–åˆ°å†…å®¹: {content}")
                                    # ä¿å­˜å†…å®¹ï¼Œå› ä¸ºæœ€åä¸€è¡Œé€šå¸¸åŒ…å«å®Œæ•´å†…å®¹
                                    complete_content = content
                        except json.JSONDecodeError as e:
                            logger.warning(f"[QWEN_API] JSONè§£æé”™è¯¯: {str(e)}, æ•°æ®éƒ¨åˆ†: {data_part}")
                            continue
                
                logger.debug(f"[QWEN_API] å“åº”æµå¤„ç†å®Œæˆï¼Œæ€»è¡Œæ•°: {len(all_lines)}")
                logger.debug(f"[QWEN_API] æœ€ç»ˆcomplete_content: '{complete_content}'")
                
                # ç¡®ä¿è¿”å›çš„æ ¼å¼ä¸BaseLLMClient.generate_responseæ–¹æ³•æœŸæœ›çš„æ ¼å¼åŒ¹é…
                if complete_content:
                    # æ„é€ ä¸€ä¸ªæ ‡å‡†æ ¼å¼çš„å“åº”ï¼Œå®Œå…¨ç¬¦åˆBaseLLMClientçš„æœŸæœ›
                    standard_response = {
                        "choices": [{
                            "message": {
                                "content": complete_content
                            }
                        }]
                    }
                    logger.debug(f"[QWEN_API] æ„é€ çš„æ ‡å‡†å“åº”: {standard_response}")
                    return standard_response
                
                logger.error("[QWEN_API] æœªèƒ½æå–åˆ°å®Œæ•´å“åº”å†…å®¹")
                logger.debug(f"[QWEN_API] æ‰€æœ‰æ¥æ”¶åˆ°çš„è¡Œ: {all_lines}")
                return None
            else:
                logger.error(f"[QWEN_API] API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
                return None
        except Exception as e:
            logger.error(f"[QWEN_API] API è¯·æ±‚å¼‚å¸¸: {str(e)}")
            import traceback
            logger.error(f"[QWEN_API] è¯¦ç»†é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return None
            
    def _call_api_stream(self, messages):
        """è°ƒç”¨DashScope APIçš„æµå¼æ¥å£"""
        url = self._get_api_url()
        headers = self._get_headers()
        payload = self._build_payload(messages, stream=True)
        
        logger.debug(f"è°ƒç”¨DashScopeæµå¼API: {url}")
        logger.debug(f"æµå¼è¯·æ±‚å¤´: {headers}")
        logger.debug(f"æµå¼è¯·æ±‚ä½“: {payload}")
        
        try:
            # ç®€åŒ–çš„æµå¼è¯·æ±‚å®ç°
            response = requests.post(url, headers=headers, json=payload, stream=True)
            
            logger.debug(f"æµå¼è¯·æ±‚çŠ¶æ€ç : {response.status_code}")
            logger.debug(f"æµå¼å“åº”å¤´: {response.headers}")
            
            line_count = 0
            chunk_count = 0
            
            for line in response.iter_lines():
                if line:
                    line_count += 1
                    decoded_line = line.decode('utf-8')
                    logger.debug(f"æµå¼ç¬¬{line_count}è¡Œ: {decoded_line}")
                    
                    # åªå¤„ç†dataè¡Œ
                    if decoded_line.startswith('data:'):
                        try:
                            # æå–dataéƒ¨åˆ†
                            data_part = decoded_line[5:].strip()
                            logger.debug(f"æ•°æ®éƒ¨åˆ†: {data_part}")
                            
                            # è§£æJSON
                            chunk = json.loads(data_part)
                            logger.debug(f"è§£æåçš„chunk: {chunk}")
                            
                            # ç›´æ¥æ£€æŸ¥å¹¶æå–content
                            if ('output' in chunk and 
                                'choices' in chunk['output'] and 
                                len(chunk['output']['choices']) > 0 and 
                                'message' in chunk['output']['choices'][0] and 
                                'content' in chunk['output']['choices'][0]['message']):
                                
                                content = chunk['output']['choices'][0]['message']['content']
                                chunk_count += 1
                                logger.debug(f"æˆåŠŸæå–ç¬¬{chunk_count}ä¸ªå†…å®¹å—: {content}")
                                
                                # ç›´æ¥yieldå†…å®¹
                                yield content
                                
                        except json.JSONDecodeError as e:
                            logger.error(f"JSONè§£æé”™è¯¯: {str(e)}, è¡Œå†…å®¹: {decoded_line}")
                        except Exception as e:
                            logger.error(f"å¤„ç†æ•°æ®å—æ—¶å‡ºé”™: {str(e)}")
            
            # ç¡®ä¿å“åº”è¢«å…³é—­
            response.close()
            
            logger.debug(f"æµå¼è°ƒç”¨å®Œæˆï¼Œå¤„ç†äº†{line_count}è¡Œï¼Œæå–äº†{chunk_count}ä¸ªå†…å®¹å—")
            
        except Exception as e:
            logger.error(f"æµå¼APIè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            raise

# ========================
# ğŸ¯ å·¥å‚ç±»ï¼šæ ¹æ®é…ç½®åˆ›å»ºå®¢æˆ·ç«¯
# ========================
class LLMClientFactory:
    @staticmethod
    def create_client(config=None) -> BaseLLMClient:
        config = config or global_config
        provider = config.MODEL_PROVIDER.lower()

        client_map = {
            "deepseek": DeepSeekClient,
            "openai": OpenAIClient,
            "moonshot": MoonshotClient,
            "qwen_dashscope": QwenDashScopeClient,
            # å¯ç»§ç»­æ‰©å±•
        }

        if provider in client_map:
            return client_map[provider](config)
        else:
            logger.warning(f"æœªçŸ¥æ¨¡å‹æä¾›å•†: {provider}ï¼Œé»˜è®¤ä½¿ç”¨ DeepSeekClient")
            return DeepSeekClient(config)


# ========================
# ğŸ å…¨å±€å®¢æˆ·ç«¯å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
# ========================
class LazyLLMClient:
    def __init__(self):
        self._client = None
        self._config = None

    def __getattr__(self, name):
        if self._client is None:
            self._client = LLMClientFactory.create_client()
            self._config = getattr(self._client, 'config', None)
            logger.info(f"LLM å®¢æˆ·ç«¯å·²åˆå§‹åŒ–ï¼Œæä¾›å•†: {getattr(self._config, 'MODEL_PROVIDER', 'æœªçŸ¥')}")
        return getattr(self._client, name)

    def validate_api_key(self) -> bool:
        """éªŒè¯ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
        
        Returns:
            API å¯†é’¥æ˜¯å¦æœ‰æ•ˆçš„å¸ƒå°”å€¼
        """
        if self._client is None:
            try:
                self._client = LLMClientFactory.create_client()
                self._config = getattr(self._client, 'config', None)
            except Exception:
                return False
        
        if hasattr(self._client, 'validate_api_key'):
            return self._client.validate_api_key()
        
        # é»˜è®¤å®ç°ï¼šæ£€æŸ¥æ˜¯å¦æœ‰APIå¯†é’¥
        return hasattr(self._client, 'api_key') and bool(getattr(self._client, 'api_key', None))

    def refresh_client(self, new_config=None):
        """åˆ·æ–°å®¢æˆ·ç«¯å®ä¾‹ï¼Œå¯ä»¥ä½¿ç”¨æ–°é…ç½®"""
        logger.info("åˆ·æ–° LLM å®¢æˆ·ç«¯å®ä¾‹")
        self._client = LLMClientFactory.create_client(new_config)
        self._config = getattr(self._client, 'config', None)
        logger.info(f"LLM å®¢æˆ·ç«¯å·²åˆ·æ–°ï¼Œæä¾›å•†: {getattr(self._config, 'MODEL_PROVIDER', 'æœªçŸ¥')}")
        return self

    def get_status(self):
        """è·å–å®¢æˆ·ç«¯çŠ¶æ€ä¿¡æ¯"""
        if self._client is None:
            return {
                "initialized": False,
                "status": "æœªåˆå§‹åŒ–"
            }
        
        try:
            is_api_valid = self.validate_api_key()
            return {
                "initialized": True,
                "provider": getattr(self._config, 'MODEL_PROVIDER', 'æœªçŸ¥'),
                "model": getattr(self._config, 'MODEL_NAME', 'æœªçŸ¥'),
                "api_key_valid": is_api_valid,
                "temperature": getattr(self._config, 'TEMPERATURE', 0.1),
                "max_tokens": getattr(self._config, 'MAX_TOKENS', 2048)
            }
        except Exception as e:
            logger.error(f"è·å–å®¢æˆ·ç«¯çŠ¶æ€å¤±è´¥: {str(e)}")
            return {
                "initialized": True,
                "error": str(e)
            }

# åˆ›å»ºå…¨å±€æ‡’åŠ è½½å®¢æˆ·ç«¯å®ä¾‹
llm_client = LazyLLMClient()